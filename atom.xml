<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="https://programelot.github.io/atom.xml" rel="self" type="application/atom+xml" /><link href="https://programelot.github.io/" rel="alternate" type="text/html" /><updated>2023-05-28T21:16:18+09:00</updated><id>https://programelot.github.io/atom.xml</id><title type="html">REAL</title><subtitle>I am Programelot who is researching about optimization.</subtitle><author><name>Programelot</name></author><entry><title type="html">Rayleigh’s theorem(Beatty’s theorem)</title><link href="https://programelot.github.io/algorithm/2023/01/30/Rayleighs-theorem/" rel="alternate" type="text/html" title="Rayleigh's theorem(Beatty's theorem)" /><published>2023-01-30T00:00:00+09:00</published><updated>2023-01-30T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/2023/01/30/Rayleighs%20theorem</id><content type="html" xml:base="https://programelot.github.io/algorithm/2023/01/30/Rayleighs-theorem/">## Theorem ##
Let's think about the sequence of $[\alpha k]$ for $k \in \mathcal{Z}^+$ and $\alpha \in \mathcal{R}^+/\mathcal{Q}^+$ and $\alpha &gt; 1$.
For example, $[\sqrt{2}] \approxeq 1.414 = 1, [2 \sqrt{2}] \approxeq 2.828 = 2, [3 \sqrt{2}] \approxeq 4.242 = 4, [4 \sqrt{2}] \approxeq 5.656 = 5, [5 \sqrt{2}] \approxeq 7.071 = 7$ for $\alpha = \sqrt{2}$.
Then, $[\alpha k]$ and $[\beta k]$ partitions an integer sequence if $\alpha^{-1} + \beta^{-1} = 1$.
For example, $\frac{1}{\sqrt{2}} + \frac{1}{\sqrt{2}/(\sqrt{2} - 1)} = \frac{1}{\sqrt{2}} + \frac{\sqrt{2} - 1}{\sqrt{2}} = 1$.
Which means $[\sqrt{2}/(\sqrt{2} - 1)] \approxeq 3.414 = 3, [2\sqrt{2}/(\sqrt{2} - 1)] \approxeq 6.828 = 6$.

## Proof ##

Proof will be done with contradictions for two parts.

### No collision ###

There is something that exists in both $[\alpha k]$ and $[\beta k]$.

Then, there is positive integer $v, r, k \in \mathcal{Z}^+$ such that $v = [\alpha r] = [\beta k]$.

Which means $v \le \alpha r &lt; v + 1$ and $ v \le \beta k &lt; v + 1$.

By dividing each by $\alpha, \beta$, $\frac{v}{\alpha} \le r &lt; \frac{v + 1}{\alpha}$ and $\frac{v}{\beta} \le k &lt; \frac{v + 1}{\beta}$.

However, equality can't be happen because $\alpha, \beta$ is irrational.

Now adding two equation results in $\frac{v}{\alpha} + \frac{v}{\beta} = v(\frac{1}{\alpha} + \frac{1}{\beta}) = v &lt; r + k &lt; \frac{v + 1}{\alpha} + \frac{v + 1}{\beta} &lt; (v + 1)(\frac{1}{\alpha} + \frac{1}{\beta}) = v + 1$.

Which result in $v &lt; r + k &lt; v + 1$ and it's a contradiction to $r + k$ is an integer.

### Coverage ###

There is something that doesn't exists in both $[\alpha k]$ and $[\beta k]$.

Then, there is positive integer $v, r, k \in \mathcal{Z}^+$ such that $[\alpha r] = v - 1, [\alpha (r + 1)] = v + 1, [\beta k] = v - 1, [\beta (k + 1)] = v + 1$.

Which means, $\alpha r &lt; v, \alpha (r + 1) \ge v + 1, \beta k &lt; v , \beta (k + 1) \ge v + 1$.

Notice that equality can't happen in here either because $\alpha, \beta$ is irrational.

By dividing $\alpha, \beta$, it results in  $r &lt; \frac{v}{\alpha}, r + 1 &gt; \frac{v + 1}{\alpha}, k &lt; \frac{v}{\beta} , k + 1 &gt; \frac{v + 1}{\beta}$.

Adding 1st and 3rd inequality, $r + k &lt; \frac{v}{\alpha} + \frac{v}{\beta} = v(\frac{1}{\alpha} + \frac{1}{\beta}) = v$.

Similarly adding 2nd and 4th inequality, $r + 1 + k + 1 &gt; \frac{v + 1}{\alpha} + \frac{v + 1}{\beta} = (v + 1)(\frac{1}{\alpha} + \frac{1}{\beta}) = v + 1$.

Which means $r + k &gt; v + 1 - 2 = v - 1$.

By using both inequality, $v - 1 &lt; r + k &lt; v$ and it's a contradiction to $r + k$ is an integer.

As a result, claim holds.</content><author><name>Programelot</name></author><summary type="html">Theorem Let’s think about the sequence of $[\alpha k]$ for $k \in \mathcal{Z}^+$ and $\alpha \in \mathcal{R}^+/\mathcal{Q}^+$ and $\alpha &amp;gt; 1$. For example, $[\sqrt{2}] \approxeq 1.414 = 1, [2 \sqrt{2}] \approxeq 2.828 = 2, [3 \sqrt{2}] \approxeq 4.242 = 4, [4 \sqrt{2}] \approxeq 5.656 = 5, [5 \sqrt{2}] \approxeq 7.071 = 7$ for $\alpha = \sqrt{2}$. Then, $[\alpha k]$ and $[\beta k]$ partitions an integer sequence if $\alpha^{-1} + \beta^{-1} = 1$. For example, $\frac{1}{\sqrt{2}} + \frac{1}{\sqrt{2}/(\sqrt{2} - 1)} = \frac{1}{\sqrt{2}} + \frac{\sqrt{2} - 1}{\sqrt{2}} = 1$. Which means $[\sqrt{2}/(\sqrt{2} - 1)] \approxeq 3.414 = 3, [2\sqrt{2}/(\sqrt{2} - 1)] \approxeq 6.828 = 6$.</summary></entry><entry><title type="html">Sum of beatty sequence</title><link href="https://programelot.github.io/algorithm/2023/01/30/Sum-of-beatty-sequence/" rel="alternate" type="text/html" title="Sum of beatty sequence" /><published>2023-01-30T00:00:00+09:00</published><updated>2023-01-30T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/2023/01/30/Sum%20of%20beatty%20sequence</id><content type="html" xml:base="https://programelot.github.io/algorithm/2023/01/30/Sum-of-beatty-sequence/"># Problem #
Let's think about the sequence of $[\alpha k]$ for $k \in \mathcal{Z}^+$ and $\alpha \in \mathcal{R}^+/\mathcal{Q}^+$ and $\alpha &gt; 1$.
For example, $[\sqrt{2}] \approxeq 1.414 = 1, [2 \sqrt{2}] \approxeq 2.828 = 2, [3 \sqrt{2}] \approxeq 4.242 = 4, [4 \sqrt{2}] \approxeq 5.656 = 5, [5 \sqrt{2}] \approxeq 7.071 = 7$ for $\alpha = \sqrt{2}$.
Let's define $S(\alpha, n) = \sum\limits_{k = 1}^{n}[\alpha k]$.
Then, problem is that compute $S(\alpha, n)$.
In general, it can be computed easily by computing one by one which takes $O(n)$.
However, there is another algorithm that takes much less time than this.

# Algorithm #

Then, $S(\alpha, n) + S(\beta, [m/\beta]) = \sum\limits_{k = 1}^{m} k$ with following conditions.
1. $\alpha^{-1} + \beta^{-1} = 1$ 
2. $m = [\alpha n]$

Proof is as follows.

First of all, due to the [Rayleigh's theorem(Beatty's theorem)](/algorithm/2023/01/30/Rayleighs-theorem), it is true that sum of two sequence can cover the interger sequence.

Secondly, it is true that $S(\beta, [m/\beta])$ covers all integers from $1$ to $m$ that exists in the $[\beta k]$ since it ends with $[m/\beta]$.

At the same time, $S(\alpha, n)$ ends with $[\alpha n] = m$. Therefore, it covers all integers from $1$ to $m$.

From the proof above, $S(\alpha, n) + S(\beta, [m/\beta]) = \sum\limits_{k = 1}^{m} k = m(m + 1)/2$

As a result, $S(\alpha, n) = m(m + 1)/2 - S(\beta, [m/\beta])$.

Now, onlything that matter is whether computing $S(\beta, [m/\beta])$ is simpler than computing $S(\alpha, n)$.

To achived this, we need to check whether $\alpha &gt; 2$ or not.

If $\alpha &gt; 2$, use the follwoing equations to reduce $\alpha$.

$S(\alpha, n) = \sum\limits_{k = 1}^{n}[\alpha k] $
$ = \sum\limits_{k = 1}^{n}[((\alpha - 1) + 1) k] $
$ = \sum\limits_{k = 1}^{n}[(\alpha - 1)k + k] $
$ = \sum\limits_{k = 1}^{n}[(\alpha - 1)k] + \sum\limits_{k = 1}^{n}k $
$ = S(\alpha - 1, n) + n(n+1)/2$

Notice that it means $S(\alpha, n) = S(\alpha - k, n) + kn(n+1)/2$ for $k \in \mathcal{Z}^{+}$ such that $k &lt; \alpha - 1$.

Now, let's assume that $1 &lt; \alpha &lt; 2$.

It is ture that $\beta = \frac{\alpha}{\alpha - 1}$ from $\alpha^{-1} + \beta^{-1} = 1$.

If $\beta$ is bigger than $2$, we can use the same process above to change it exists between $1$ and $2$.

Therefore, only consideration is whether $[m/\beta]$ is smaller than $n$ or not.

And it is true from $[m/\beta] = [[\alpha n]/\beta] = [[\alpha n]/(\alpha/(\alpha - 1))] \le ((\alpha n)/\alpha)(\alpha - 1) = (\alpha - 1) n &lt; n$.

Notice that $ 0 &lt; \alpha - 1 &lt; 1$.

As a result, it makes problem simpler.

Notice that this algorithm is faster since it reduces number to be computed in some ratio.

Therefore, it usually faster than computing it one by one.

# Example #

For example, $S(\sqrt{2}, 100)$ can be computed as follows.
Notice that $\alpha = \sqrt{2}$ then $\beta = \frac{\sqrt{2}}{\sqrt{2} - 1} = 2 + \sqrt{2}$

1. $S(\sqrt{2}, 100) = 141 * 142 / 2 - S(2 + \sqrt{2}, 41)$ by $m = [\sqrt{2} *  100] = 141, [m/\beta] = 41$.
2. $S(2 + \sqrt{2}, 41) = S(\sqrt{2}, 41) + 2 * 41 * 42/2$
3. $S(\sqrt{2}, 41) = 57 * 58 / 2 - S(2 + \sqrt{2}, 16)$ by $m = [\sqrt{2} *  100] = 57, [m/\beta] = 16$.
4. $S(2 + \sqrt{2}, 16) = S(\sqrt{2}, 16) + 2 * 16 * 17/2$
5. $S(\sqrt{2}, 16) = 22 * 23 / 2 - S(2 + \sqrt{2}, 6)$ by $m = [\sqrt{2} *  16] = 22, [m/\beta] = 6$.
6. $S(2 + \sqrt{2}, 6) = S(\sqrt{2}, 6) + 2 * 6 * 7/2$
7. $S(\sqrt{2}, 6) = 8 * 9 / 2 - S(2 + \sqrt{2}, 2)$ by $m = [\sqrt{2} *  6] = 8, [m/\beta] = 2$.
8. $S(2 + \sqrt{2}, 2) = S(\sqrt{2}, 2) + 2 * 2 * 3/2$
9. $S(\sqrt{2}, 2) = 2 * 3 / 2 - S(2 + \sqrt{2}, 0)$ by $m = [\sqrt{2} *  2] = 2, [m/\beta] = 0$.
10. $S(2 + \sqrt{2}, 0) = 0$
11. $S(\sqrt{2}, 2) = 2 * 3 / 2 - S(2 + \sqrt{2}, 0) = 3 - 0 = 3$
12. $S(2 + \sqrt{2}, 2) = S(\sqrt{2}, 2) + 2 * 2 * 3/2 = 3 + 6 = 9$
13. $S(\sqrt{2}, 6) = 8 * 9 / 2 - S(2 + \sqrt{2}, 2) = 36 - 9 = 27$ 
14. $S(2 + \sqrt{2}, 6) = S(\sqrt{2}, 6) + 2 * 6 * 7/2 = 27 + 42 = 69$
15. $S(\sqrt{2}, 16) = 22 * 23 / 2 - S(2 + \sqrt{2}, 6) = 253 - 69 = 184$
16. $S(2 + \sqrt{2}, 16) = S(\sqrt{2}, 16) + 2 * 16 * 17/2 = 184 + 272 = 456$
17. $S(\sqrt{2}, 41) = 57 * 58 / 2 - S(2 + \sqrt{2}, 16) = 1653 - 456 = 1197$
18. $S(2 + \sqrt{2}, 41) = S(\sqrt{2}, 41) + 2 * 41 * 42/2 = 1197 + 1722 = 2919$
19.  $S(\sqrt{2}, 100) = 141 * 142 / 2 - S(2 + \sqrt{2}, 41) = 10011 - 2919 = 7092$</content><author><name>Programelot</name></author><summary type="html">Problem Let’s think about the sequence of $[\alpha k]$ for $k \in \mathcal{Z}^+$ and $\alpha \in \mathcal{R}^+/\mathcal{Q}^+$ and $\alpha &amp;gt; 1$. For example, $[\sqrt{2}] \approxeq 1.414 = 1, [2 \sqrt{2}] \approxeq 2.828 = 2, [3 \sqrt{2}] \approxeq 4.242 = 4, [4 \sqrt{2}] \approxeq 5.656 = 5, [5 \sqrt{2}] \approxeq 7.071 = 7$ for $\alpha = \sqrt{2}$. Let’s define $S(\alpha, n) = \sum\limits_{k = 1}^{n}[\alpha k]$. Then, problem is that compute $S(\alpha, n)$. In general, it can be computed easily by computing one by one which takes $O(n)$. However, there is another algorithm that takes much less time than this.</summary></entry><entry><title type="html">Stack and queue</title><link href="https://programelot.github.io/algorithm/2021/08/13/Stack-Queue/" rel="alternate" type="text/html" title="Stack and queue" /><published>2021-08-13T00:00:00+09:00</published><updated>2021-08-13T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/2021/08/13/Stack%20Queue</id><content type="html" xml:base="https://programelot.github.io/algorithm/2021/08/13/Stack-Queue/">There is another data strucutre that used to store tons of data.
Therefore, it has two special operations known as the insert and the pop.
However, there are two types of ways to make policies for inserting and poping a data from a structure.

Depending on this two method, it is so-called as a stack or a queue.
Stack has a property known as LIFO(Last-In-First-Out).
Queue has a property known as FIFO(First-In-First-Out).

## Stack ##
If we insert a data into a stack first, it should be popped from the stack first.
Therefore, it reserves the order we inserted even when it is popped.

## Queue ##
If we insert a data into a queue first, it should be popped from the stack later.
Therefore, it reverses the order we inserted even when it is popped.

## Complexity ##
If we use a list for implementing a stack and a queue, it is easy to get a good performance because we already has $O(1)$ complexity for inserting and deleting at the front and the end of the list.

| Time complexity  | Stack   | Queue   | 
| ---          | --- | --- | 
| Insert           | $O(1)$  | $O(1)$  |
| Pop              | $O(1)$  | $O(1)$  |
| Space complexity | $O(n)$  | $O(n)$  |</content><author><name>Programelot</name></author><summary type="html">There is another data strucutre that used to store tons of data. Therefore, it has two special operations known as the insert and the pop. However, there are two types of ways to make policies for inserting and poping a data from a structure.</summary></entry><entry><title type="html">Array and list</title><link href="https://programelot.github.io/algorithm/2021/08/12/Array-List/" rel="alternate" type="text/html" title="Array and list" /><published>2021-08-12T00:00:00+09:00</published><updated>2021-08-12T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/2021/08/12/Array%20List</id><content type="html" xml:base="https://programelot.github.io/algorithm/2021/08/12/Array-List/">Before talking about algorithm itself, we need to talk about data structures that typically uses for algorithms.
Some of algorithms even works based on a specific data structure that optimizes the algorithm.
In this chapter, I'll explain the most common data structures only.

## Array ##

To store a number of data, there should be some data structure that can give a specific data you want anytime and store a data in to the storage either.
To acheive this property, there is the easiest data structure known as an array.
Like the name itself, it stores data in an array of storage.
Pros of this algorithm is that you can get a data anytime from an array in a constant time because all you need is an index.
In mathmatical format, it usually written as $a[0]$ or $a_0$.
However, there is a big disadvantange for this.
If you want to use an array, you need to know exact size of data you need.
Otherwise, you may can access to the data where you didn't meant to.
Therefore, it has a big disadvantage known as the fixed-size.
However, it can extend the array by making a new array and copy every element in side of the array.
Therefore, complexity of an array is like follow.

| Time complexity  | Array   |
| ---          | --- | 
| Search/Change    | $O(1)$  |
| Add (Front)      | $O(n)$  |
| Add (Random)     | $O(n)$  |
| Add (Back)       | $O(n)$  |
| Delete (Front)   | $O(n)$  |
| Delete (Random)  | $O(n)$  |
| Delete (Back)    | $O(n)$  |
| Merge            | $O(n)$  |
| Space complexity | $O(n)$  |

Notice that adding and delete will change the size of the array.
Merge means that merging two array into a single array.
It will be assumed to have the same size of two arrays.

## List 1 ##

To avoid this fixed-size problem, there is an alternative structure known as a list.
A list consists of nodes.
Each node has a data and a pointer to the next node.
Therefore, it can access to next node from any node.
However, it has a slow search algorithm because it can access only the next node.
Therefore, it takes a linear time to read an array.

| Time complexity  | List 1  |
| ---          | --- | 
| Search/Change    | $O(n)$  |
| Add (Front)      | $O(1)$  |
| Add (Random)     | $O(n)$  |
| Add (Back)       | $O(n)$  |
| Delete (Front)   | $O(1)$  |
| Delete (Random)  | $O(n)$  |
| Delete (Back)    | $O(n)$  |
| Merge            | $O(n)$  |
| Space complexity | $O(n)$  |

One other problem is that it can only add the new data without overhead at the front of the list.
Therefore, there is another ways to make a list.

## List 2 ##

What if we make a pointer to denotes the last point of the list at the same time?
It will gives an advantages that makes accessable at the end of the list.
Therefore, it will give better performance when it works for the end of the list.
At the same time, it has an advantage to merge two lists because it can connect the end point of a list to another list.

| Time complexity  | List 2  |
| ---          | --- | 
| Search/Change    | $O(n)$  |
| Add (Front)      | $O(1)$  |
| Add (Random)     | $O(n)$  |
| Add (Back)       | $O(1)$  |
| Delete (Front)   | $O(1)$  |
| Delete (Random)  | $O(n)$  |
| Delete (Back)    | $O(1)$  |
| Merge            | $O(1)$  |
| Space complexity | $O(n)$  |

However, it still has $O(n)$ complexity for read/change operation.
Therefore, it usually doesn't be used in actual implementation however the notation of the list is typically used for many other data structures.

## Vector ##

Last implementation is which standard c++ language uses.
It works like an ordinary array but it increases its size by double the size.
It gives a nice performance because it gives a constant complexity for adding and deleting data at the back of the array.
Notice that this is amortized analysis.
Therefore, it sometimes cause long term process.

| Time complexity  | Vector           |
| ---          | ---          | 
| Search/Change    | $O(1)$           |
| Add (Front)      | $O(n)$           |
| Add (Random)     | $O(n)$           |
| Add (Back)       | Amortized $O(1)$ |
| Delete (Front)   | $O(n)$           |
| Delete (Random)  | $O(n)$           |
| Delete (Back)    | Amortized $O(1)$ |
| Merge            | $O(n)$           |
| Space complexity | $O(n)$           |

## Comparison ##

| Time complexity  | Array   | List 1  | List 2  | Vector           |
| ---          | --- | --- | --- | ---          | 
| Search/Change    | $O(1)$  | $O(n)$  | $O(n)$  | $O(1)$           |
| Add (Front)      | $O(n)$  | $O(1)$  | $O(1)$  | $O(n)$           |
| Add (Random)     | $O(n)$  | $O(n)$  | $O(n)$  | $O(n)$           |
| Add (Back)       | $O(n)$  | $O(n)$  | $O(1)$  | Amortized $O(1)$ |
| Delete (Front)   | $O(n)$  | $O(1)$  | $O(1)$  | $O(n)$           |
| Delete (Random)  | $O(n)$  | $O(n)$  | $O(n)$  | $O(n)$           |
| Delete (Back)    | $O(n)$  | $O(n)$  | $O(1)$  | Amortized $O(1)$ |
| Merge            | $O(n)$  | $O(n)$  | $O(1)$  | $O(n)$           |
| Space complexity | $O(n)$  | $O(n)$  | $O(n)$  | $O(n)$           |</content><author><name>Programelot</name></author><summary type="html">Before talking about algorithm itself, we need to talk about data structures that typically uses for algorithms. Some of algorithms even works based on a specific data structure that optimizes the algorithm. In this chapter, I’ll explain the most common data structures only.</summary></entry><entry><title type="html">Complexity</title><link href="https://programelot.github.io/algorithm/2021/08/10/Complexity/" rel="alternate" type="text/html" title="Complexity" /><published>2021-08-10T00:00:00+09:00</published><updated>2021-08-10T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/2021/08/10/Complexity</id><content type="html" xml:base="https://programelot.github.io/algorithm/2021/08/10/Complexity/">To analyze performances of algorithms, we need to define some jargons.

## Time complexity ##

The time complexity of an algorithm, $T(n)$ is a function that denotes running time of the algorithm depending on the size of input data.
For example, let's think about an algorithm that adds data with other data.
You may smart enough to add any arbitrary two number in 1 second.
Then, how many time will it took for 100 data?
It will be 100 seconds.
In this case, $T(n) = n$.

## Big O notation ##

Big O notation is the method to guarantee the upper bound of algorithms' perforamce.
For any time complexity $T(n)$, we say $T(n)$ $=$ $O(g(n))$ if there is some positive constant $M$,$x_0$ such that $T(n)$ $\le$ $M g(n)$ for all $x \ge x_0$.
For example, if $T(n)$ $=$ $n^3$ $+$ $10n^2$ $+$ $n$ $+$ $27$, $T(n)$ $=$ $O(n^3)$ for $M$ $=$ $39$, $x_0$ $=$ $1$.
Notice that $T(n)$ $=$ $n^3$ $+$ $10n^2$ $+$ $n$ $+$ $27$ $\le$ $n^3$ $+$ $10n^3$ $+$ $n^3$ $+$ $27n^3$ $=$ $39n^3$ for $n$ $\ge$ $1$.
In fact, it is enough to find the most steepest part in $T(n)$.

## Asymptotically approximate ##

In fact, it can be choosed to be worse than expected in big O notation.
For example, $T(n)$ $=$ $O(n^2)$ if $T(n)$ $=$ $O(n)$ in all cases.
Therefore, we say that &quot;An algorithm's time complexity asymptotically approximates to $g(n)$&quot; when $\lim\limits_{n \leftarrow \infty}\frac{T(n)}{Mg(n)} = 1$ for some positive constant $M$.

## Big $\Omega$ notation ##

Big $\Omega$ notation is the opposite with the big O notation.
It guarantess the lower bound of algorithms' performance.
For any time complexity $T(n)$, we say $T(n)$ $=$ $\Omega(g(n))$ if there is some positive constant $M$,$x_0$ such that $T(n)$ $\ge$ $M g(n)$ for all $x \ge x_0$.

## Big $\Theta$ notation ##

Big theta notation is used when an algorithm has the same complexity for both upper and lower bounds.
In other word, we say $T(n)$ $=$ $\Theta(g(n))$ if there is some positive constant $M1$,$M_2$,$x_0$ such that $M_2 g(n)$ $\le$ $T(n)$ $\le$ $M_1 g(n)$ for all $x \ge x_0$.
However, it is hard to expect that algorithm has such a complexity.
Some algorithms' performance vary between the data itself.
Therefore, some algorithm can't have big $\Theta$ notation for their time complexity.

## Amortized complexity ##

Amortized complexity is another measurement to analysis an algorithm.
Many algorithms doesn't have a nice $\Theta$ notation to explain the performance's performance.
It really depends on the situation.
However, it can be pessimistic to use only big O notation.
Therefore, amortized complexity measures a performance of an algorithm by dividing its complexity between executions.
If some algorithm works $O(1)$ for $n$ times and it works $O(n^2)$ for $1$ time.
Then, the amortized complexity of this algorithm is $O(\frac{1 \times n + n^2}{n + 1})$ $=$ $O(n)$.

## Space complexity ##

Space complexity is another measurable tool for algorithms.
It denotes how many memory spaces it uses.
We use all of notations above to represent space complexity either.</content><author><name>Programelot</name></author><summary type="html">To analyze performances of algorithms, we need to define some jargons.</summary></entry><entry><title type="html">Algorithm</title><link href="https://programelot.github.io/algorithm/2021/08/02/Algorithm/" rel="alternate" type="text/html" title="Algorithm" /><published>2021-08-02T00:00:00+09:00</published><updated>2021-08-02T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/2021/08/02/Algorithm</id><content type="html" xml:base="https://programelot.github.io/algorithm/2021/08/02/Algorithm/">Algorithm is a mathmatical tool to solve some problem with propal methods.
For example, let's think about a situation follows.
Oneday, you've got a job from a city library.
However, there was a tournado yesterday so all books dropped out of the shelf.
Your employer calls you and asks you to clean it up in order of books' ID.
Despite of your low payment, you have no way but clean it up.
Therefore, you started to think about the way to clean it up.

## Insertion sort ##
You may give up to think about better way to clean it up.
Instead of it, you just started to clean it up by reading the ID of each book and put the book which has the smallest ID into the shelf.

## Quick sort ##
While you are doing such a thing, your friend decided to do the follow.
1. If there is only one book, just put it in with the revered direction.
2. If there is more than a book, select a book in random.
3. Put all books that have smaller ID than the book that you selected at 1 into the shelf.
4. Then add the book that you selected at 1 but in the reversed direction to identify this is the book which you used.
5. If all books are in the self with inverse direction, flip all books.
6. Otherwise, pick books between two reversed book and take books out of the shelf and do the same process from 1.

Notice that the starting point, end point of the shelf will be considered as the reversed book in 6.

This looks more complex but it usually takes much less time than you did.
See the example below.

## Example ##
For example, there are books that have IDs of 52,33,25,19,28,38,37,45,73,68,61,69,87,78,90.
Now, let's follow the each process.

You will clean the book like bellow.
Notice that I marked [] as books that shelf has, {} as what you are memorizing and () as what you are looking.
In this algorithm, you can see only one book at once because numbers are too complex to see it on glance.
At the same time, you can memorize a number at most because of its long digits.

1. (52), 33, 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
2. {52}, (33), 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
3. 52, {33}, (25), 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
4. 52, 33, {25}, (19), 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
5. 52, 33, 25, {19}, (28), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
6. 52, 33, 25, {19}, 28, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
7. 52, 33, 25, {19}, 28, 38, (37), 45, 73, 68, 61, 69, 87, 78, 90
8. 52, 33, 25, {19}, 28, 38, 37, (45), 73, 68, 61, 69, 87, 78, 90
9. 52, 33, 25, {19}, 28, 38, 37, 45, (73), 68, 61, 69, 87, 78, 90
10. 52, 33, 25, {19}, 28, 38, 37, 45, 73, (68), 61, 69, 87, 78, 90
11. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, (61), 69, 87, 78, 90
12. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, 61, (69), 87, 78, 90
13. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, 61, 69, (87), 78, 90
14. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, 61, 69, 87, (78), 90
15. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, (90)
16. [19], 52, 33, 25, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
17. [19], (52), 33, 25, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
18. [19], {52}, (33), 25, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
19. [19], 52, {33}, (25), 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
20. [19], 52, 33, {25}, (28), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
21. [19], 52, 33, {25}, 28, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
22. [19], 52, 33, {25}, 28, 38, (37), 45, 73, 68, 61, 69, 87, 78, 90
23. [19], 52, 33, {25}, 28, 38, 37, (45), 73, 68, 61, 69, 87, 78, 90
24. [19], 52, 33, {25}, 28, 38, 37, 45, (73), 68, 61, 69, 87, 78, 90
25. [19], 52, 33, {25}, 28, 38, 37, 45, 73, (68), 61, 69, 87, 78, 90
26. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, (61), 69, 87, 78, 90
27. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, 61, (69), 87, 78, 90
28. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, 61, 69, (87), 78, 90
29. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, 61, 69, 87, (78), 90
30. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, (90)
31. [19, 25], 52, 33, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
32. [19, 25], (52), 33, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
33. [19, 25], {52}, (33), 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
34. [19, 25], 52, {33}, (28), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
35. [19, 25], 52, 33, {28}, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
36. [19, 25], 52, 33, {28}, 38, (37), 45, 73, 68, 61, 69, 87, 78, 90
37. [19, 25], 52, 33, {28}, 38, 37, (45), 73, 68, 61, 69, 87, 78, 90
38. [19, 25], 52, 33, {28}, 38, 37, 45, (73), 68, 61, 69, 87, 78, 90
39. [19, 25], 52, 33, {28}, 38, 37, 45, 73, (68), 61, 69, 87, 78, 90
40. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, (61), 69, 87, 78, 90
41. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, 61, (69), 87, 78, 90
42. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, 61, 69, (87), 78, 90
43. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, 61, 69, 87, (78), 90
44. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, 61, 69, 87, 78, (90)
45. [19, 25, 28], 52, 33, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
46. [19, 25, 28], (52), 33, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
47. [19, 25, 28], {52}, (33), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
48. [19, 25, 28], 52, {33}, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
49. [19, 25, 28], 52, {33}, 38, (37), 45, 73, 68, 61, 69, 87, 78, 90
50. [19, 25, 28], 52, {33}, 38, 37, (45), 73, 68, 61, 69, 87, 78, 90
51. [19, 25, 28], 52, {33}, 38, 37, 45, (73), 68, 61, 69, 87, 78, 90
52. [19, 25, 28], 52, {33}, 38, 37, 45, 73, (68), 61, 69, 87, 78, 90
53. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, (61), 69, 87, 78, 90
54. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, 61, (69), 87, 78, 90
55. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, 61, 69, (87), 78, 90
56. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, 61, 69, 87, (78), 90
57. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, 61, 69, 87, 78, (90)
58. [19, 25, 28, 33], 52, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
59. [19, 25, 28, 33], (52), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
60. [19, 25, 28, 33], {52}, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
61. [19, 25, 28, 33], 52, {38}, (37), 45, 73, 68, 61, 69, 87, 78, 90
62. [19, 25, 28, 33], 52, 38, {37}, (45), 73, 68, 61, 69, 87, 78, 90
63. [19, 25, 28, 33], 52, 38, {37}, 45, (73), 68, 61, 69, 87, 78, 90
64. [19, 25, 28, 33], 52, 38, {37}, 45, 73, (68), 61, 69, 87, 78, 90
65. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, (61), 69, 87, 78, 90
66. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, 61, (69), 87, 78, 90
67. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, 61, 69, (87), 78, 90
68. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, 61, 69, 87, (78), 90
69. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, 61, 69, 87, 78, (90)
70. [19, 25, 28, 33, 37], 52, 38, 45, 73, 68, 61, 69, 87, 78, 90
71. [19, 25, 28, 33, 37], (52), 38, 45, 73, 68, 61, 69, 87, 78, 90
72. [19, 25, 28, 33, 37], {52}, (38), 45, 73, 68, 61, 69, 87, 78, 90
73. [19, 25, 28, 33, 37], 52, {38}, (45), 73, 68, 61, 69, 87, 78, 90
74. [19, 25, 28, 33, 37], 52, {38}, 45, (73), 68, 61, 69, 87, 78, 90
75. [19, 25, 28, 33, 37], 52, {38}, 45, 73, (68), 61, 69, 87, 78, 90
76. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, (61), 69, 87, 78, 90
77. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, 61, (69), 87, 78, 90
78. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, 61, 69, (87), 78, 90
79. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, 61, 69, 87, (78), 90
80. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, 61, 69, 87, 78, (90)
81. [19, 25, 28, 33, 37, 38], 52, 45, 73, 68, 61, 69, 87, 78, 90
82. [19, 25, 28, 33, 37, 38], (52), 45, 73, 68, 61, 69, 87, 78, 90
83. [19, 25, 28, 33, 37, 38], {52}, (45), 73, 68, 61, 69, 87, 78, 90
84. [19, 25, 28, 33, 37, 38], 52, {45}, (73), 68, 61, 69, 87, 78, 90
85. [19, 25, 28, 33, 37, 38], 52, {45}, 73, (68), 61, 69, 87, 78, 90
86. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, (61), 69, 87, 78, 90
87. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, 61, (69), 87, 78, 90
88. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, 61, 69, (87), 78, 90
89. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, 61, 69, 87, (78), 90
90. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, 61, 69, 87, 78, (90)
91. [19, 25, 28, 33, 37, 38, 45], 52, 73, 68, 61, 69, 87, 78, 90
92. [19, 25, 28, 33, 37, 38, 45], (52), 73, 68, 61, 69, 87, 78, 90
93. [19, 25, 28, 33, 37, 38, 45], {52}, (73), 68, 61, 69, 87, 78, 90
94. [19, 25, 28, 33, 37, 38, 45], {52}, 73, (68), 61, 69, 87, 78, 90
95. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, (61), 69, 87, 78, 90
96. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, 61, (69), 87, 78, 90
97. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, 61, 69, (87), 78, 90
98. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, 61, 69, 87, (78), 90
99. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, 61, 69, 87, 78, (90)
100. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, 61, 69, 87, 78, 90
101. [19, 25, 28, 33, 37, 38, 45, 52], (73), 68, 61, 69, 87, 78, 90
102. [19, 25, 28, 33, 37, 38, 45, 52], {73}, (68), 61, 69, 87, 78, 90
103. [19, 25, 28, 33, 37, 38, 45, 52], 73, {68}, (61), 69, 87, 78, 90
104. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, {61}, (69), 87, 78, 90
105. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, {61}, 69, (87), 78, 90
106. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, {61}, 69, 87, (78), 90
107. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, {61}, 69, 87, 78, (90)
108. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, 68, 69, 87, 78, 90
109. [19, 25, 28, 33, 37, 38, 45, 52, 61], (73), 68, 69, 87, 78, 90
110. [19, 25, 28, 33, 37, 38, 45, 52, 61], {73}, (68), 69, 87, 78, 90
111. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, {68}, (69), 87, 78, 90
112. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, {68}, 69, (87), 78, 90
113. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, {68}, 69, 87, (78), 90
114. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, {68}, 69, 87, 78, (90)
115. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], 73, 69, 87, 78, 90
116. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], (73), 69, 87, 78, 90
117. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], {73}, (69), 87, 78, 90
118. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], 73, {69}, (87), 78, 90
119. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], 73, {69}, 87, (78), 90
120. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], 73, {69}, 87, 78, (90)
121. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], 73, 87, 78, 90
122. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], (73), 87, 78, 90
123. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], {73}, (87), 78, 90
124. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], {73}, 87, (78), 90
125. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], {73}, 87, 78, (90)
126. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73], 87, 78, 90
127. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73], (87), 78, 90
128. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73], {87}, (78), 90
129. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73], 87, {78}, (90)
130. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78], 87, 90
131. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78], (87), 90
132. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78], {87}, (90)
133. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87], 90
134. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87], (90)
135. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87, 90]

As a result, it takes 135 steps.
However, your friend can get a result like below.
Notice that I marked revered book by !.


1. (52), 33, 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
2. {52}, (33), 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
3. [33], {52}, 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
4. [33], {52}, (25), 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
5. [33, 25], {52}, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
6. [33, 25], {52}, (19), 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
7. [33, 25, 19], {52}, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
8. [33, 25, 19], {52}, (28), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
9. [33, 25, 19, 28], {52}, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
10. [33, 25, 19, 28], {52}, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
11. [33, 25, 19, 28, 38], {52}, 37, 45, 73, 68, 61, 69, 87, 78, 90
12. [33, 25, 19, 28, 38], {52}, (37), 45, 73, 68, 61, 69, 87, 78, 90
13. [33, 25, 19, 28, 38, 37], {52}, 45, 73, 68, 61, 69, 87, 78, 90
14. [33, 25, 19, 28, 38, 37], {52}, (45), 73, 68, 61, 69, 87, 78, 90
15. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, 69, 87, 78, 90
16. [33, 25, 19, 28, 38, 37, 45], {52}, (73), 68, 61, 69, 87, 78, 90
17. [33, 25, 19, 28, 38, 37, 45], {52}, 73, (68), 61, 69, 87, 78, 90
18. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, (61), 69, 87, 78, 90
19. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, (69), 87, 78, 90
20. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, 69, (87), 78, 90
21. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, 69, 87, (78), 90
22. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, 69, 87, 78, (90)
23. [33, 25, 19, 28, 38, 37, 45, !52!], 73, 68, 61, 69, 87, 78, 90
24. [33, 25, 19, 28, 38, 37, 45, !52!], (73), 68, 61, 69, 87, 78, 90
25. [33, 25, 19, 28, 38, 37, 45, !52!], {73}, (68), 61, 69, 87, 78, 90
26. [33, 25, 19, 28, 38, 37, 45, !52!, 68], {73}, 61, 69, 87, 78, 90
27. [33, 25, 19, 28, 38, 37, 45, !52!, 68], {73}, (61), 69, 87, 78, 90
28. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61], {73}, 69, 87, 78, 90
29. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61], {73}, (69), 87, 78, 90
30. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69], {73}, 87, 78, 90
31. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69], {73}, (87), 78, 90
32. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69], {73}, 87, (78), 90
33. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69], {73}, 87, 78, (90)
34. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!], 87, 78, 90
35. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!], (87), 78, 90
36. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!], {87}, (78), 90
37. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78], {87}, 90
38. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78], {87}, (90)
39. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78, !87!], 90
40. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78, !87!], (90)
41. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78, !87!, !90!]
42. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61], 69, [!73!, 78, !87!, !90!]
43. [33, 25, 19, 28, 38, 37, 45, !52!, 68], 61, 69, [!73!, 78, !87!, !90!]
44. [33, 25, 19, 28, 38, 37, 45, !52!], 68, 61, 69, [!73!, 78, !87!, !90!]
45. [33, 25, 19, 28, 38, 37, 45, !52!], (68), 61, 69, [!73!, 78, !87!, !90!]
46. [33, 25, 19, 28, 38, 37, 45, !52!], {68}, (61), 69, [!73!, 78, !87!, !90!]
47. [33, 25, 19, 28, 38, 37, 45, !52!, 61], {68}, 69, [!73!, 78, !87!, !90!]
48. [33, 25, 19, 28, 38, 37, 45, !52!, 61], {68}, (69), [!73!, 78, !87!, !90!]
49. [33, 25, 19, 28, 38, 37, 45, !52!, 61, !68!], 69, [!73!, 78, !87!, !90!]
50. [33, 25, 19, 28, 38, 37, 45, !52!, 61, !68!], (69), [!73!, 78, !87!, !90!]
51. [33, 25, 19, 28, 38, 37, 45, !52!, 61, !68!, !69!, !73!, 78, !87!, !90!]
52. [33, 25, 19, 28, 38, 37, 45, !52!], 61, [!68!, !69!, !73!, 78, !87!, !90!]
53. [33, 25, 19, 28, 38, 37, 45, !52!], (61), [!68!, !69!, !73!, 78, !87!, !90!]
54. [33, 25, 19, 28, 38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
55. 33, [25, 19, 28, 38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
56. 33, 25, [19, 28, 38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
57. 33, 25, 19, [28, 38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
58. 33, 25, 19, 28, [38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
59. 33, 25, 19, 28, 38, [37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
60. 33, 25, 19, 28, 38, 37, [45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
61. 33, 25, 19, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
62. (33), 25, 19, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
63. {33}, (25), 19, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
64. [25], {33}, 19, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
65. [25], {33}, (19), 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
66. [25, 19], {33}, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
67. [25, 19], {33}, (28), 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
68. [25, 19, 28], {33}, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
69. [25, 19, 28], {33}, (38), 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
70. [25, 19, 28], {33}, 38, (37), 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
71. [25, 19, 28], {33}, 38, 37, (45), [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
72. [25, 19, 28, !33!], 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
73. [25, 19, 28, !33!], (38), 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
74. [25, 19, 28, !33!], {38}, (37), 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
75. [25, 19, 28, !33!, 37], {38}, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
76. [25, 19, 28, !33!, 37], {38}, (45), [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
77. [25, 19, 28, !33!, 37, !38!], 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
78. [25, 19, 28, !33!, 37, !38!], (45), [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
79. [25, 19, 28, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
80. 25, [19, 28, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
81. 25, 19, [28, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
82. 25, 19, 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
83. (25), 19, 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
84. {25}, (19), 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
85. [19], {25}, 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
86. [19], {25}, (28), [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
87. [19, !25!], 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
88. [19, !25!], (28), [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
89. [19, !25!, !28!, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
90. 19, [!25!, !28!, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
91. (19), [!25!, !28!, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
92. [!19!, !25!, !28!, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
93. [!19!, !25!, !28!, !33!], 37, [!38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
94. [!19!, !25!, !28!, !33!], (37), [!38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
95. [!19!, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
96. [!19!, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!], 78, [!87!, !90!]
97. [!19!, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!], (78), [!87!, !90!]
98. [!19!, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
99. [19, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
100. [19, 25, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
101. [19, 25, 28, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
102. [19, 25, 28, 33, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
103. [19, 25, 28, 33, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
104. [19, 25, 28, 33, 37, 38, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
105. [19, 25, 28, 33, 37, 38, 45, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
106. [19, 25, 28, 33, 37, 38, 45, 52, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
107. [19, 25, 28, 33, 37, 38, 45, 52, 61, !68!, !69!, !73!, !78!, !87!, !90!]
108. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, !69!, !73!, !78!, !87!, !90!]
109. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, !73!, !78!, !87!, !90!]
110. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, !78!, !87!, !90!]
111. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, !87!, !90!]
112. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87, !90!]
113. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87, 90]

As a result, your friend can get a result in 113 step.
Which means 19% faster than you are.

To solve this problem, we call both methods as sorting algorithms.
However, it shows different perforamce as you can see.
From the next time, it will focused on the performance of the algorithm and comparison between them.</content><author><name>Programelot</name></author><summary type="html">Algorithm is a mathmatical tool to solve some problem with propal methods. For example, let’s think about a situation follows. Oneday, you’ve got a job from a city library. However, there was a tournado yesterday so all books dropped out of the shelf. Your employer calls you and asks you to clean it up in order of books’ ID. Despite of your low payment, you have no way but clean it up. Therefore, you started to think about the way to clean it up.</summary></entry><entry><title type="html">Hardness of approximation</title><link href="https://programelot.github.io/algorithm/approximation/2021/05/28/Hardness-of-approximation/" rel="alternate" type="text/html" title="Hardness of approximation" /><published>2021-05-28T00:00:00+09:00</published><updated>2021-05-28T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/approximation/2021/05/28/Hardness%20of%20approximation</id><content type="html" xml:base="https://programelot.github.io/algorithm/approximation/2021/05/28/Hardness-of-approximation/">MAX-E3SAT is a problem that finds a truth value assignment that satisfies the maximum number of clauses for a given a set of clause which contains exactly three literals.

MAX-2SAT is a problem that finds a truth value assignment that satisfies the maximum number of clauses for a given a set of clauses which contains at most two literals.

Then there exists a $\frac{7}{8}$-approximation algorithm for MAX-E3SAT problem.

Proof is like follow.
If you see all of the clauses and count the existance of each literals and complementary of literals.
Then, we can pick at least half of them to be satisfied by pick $x_i$ or $\overline{x_i}$.
Then, we can cover at least $\frac{7}{8}$ of them because we have three literals for one clauses.

Then, P=NP if there exists a $(\frac{7}{8} + \epsilon)$-approximation algorithm for MAX-E3SAT problem for all constant $\epsilon &gt; 0$.

Proof will be updated later.

Then there exists no $\alpha$-approximation for MAX 2SAT for any constant $\alpha &gt; \frac{433}{440}$ unless P=NP.

Proof is like follow.

First of all, let's think about follow.

For three literals $l1$, $l2$ and $l3$, consider the follwing set of ten clauses in terms of $l1, l2, l3$ and auxiliary variable $y$.

1.  $l1$
2.  $l2$
3.  $l3$
4.  $\overline{l1}\lor\overline{l2}$
5.  $\overline{l2}\lor\overline{l3}$
6.  $\overline{l1}\lor\overline{l3}$
7.  $y$
8.  $l1\lor\overline{y}$
9.  $l2\lor\overline{y}$
10. $l3\lor\overline{y}$

If $l1 \lor l2 \lor l3$ is satisfied, we can choose the value of $y$ so that exactly seven of the ten clauses are satisfied and it is impossible to satisfy more than that.
If $l1 \lor l2 \lor l3$ is not satisfied, we can choose the value of $y$ so that exactly six of the ten clauses are satisfied and it is impossible to satisfy more than that.

Notice that we can have following table with number of satisfied clauses if $y$ is true.

| # true literals   | # true clauses in 1~3   | # true clauses in 4~6   | # true clauses in 7~10          | # true clauses in Total       |
| ---           | ---               | ---               | ---                       | ---                     |
| 3                 | 3                     | 0                     | 4                             | 7                           |
| 2                 | 2                     | 2                     | 3                             | 7                           |
| 1                 | 1                     | 3                     | 2                             | 6                           |
| 0                 | 0                     | 3                     | 1                             | 4                           |

If $y$ is false then number of satisfied clauses is like below.

| # true literals   | # true clauses in 1~3   | # true clauses in 4~6   | # true clauses in 7~10          | # true clauses in Total       |
| ---           | ---               | ---               | ---                       | ---                     |
| 3                 | 3                     | 0                     | 3                             | 6                           |
| 2                 | 2                     | 2                     | 3                             | 7                           |
| 1                 | 1                     | 3                     | 3                             | 7                           |
| 0                 | 0                     | 3                     | 3                             | 6                           |

As a result, maximum is follow.

| # true literals   | # true clauses in 1~3   | # true clauses in 4~6   | # true clauses in 7~10 (best)   | # true clauses in Total(best) |
| ---           | ---               | ---               | ---                       | ---                     |
| 3                 | 3                     | 0                     | 4 ($y$ as true)               | 7                           |
| 2                 | 2                     | 2                     | 3 ($y$ as true/false)         | 7                           |
| 1                 | 1                     | 3                     | 3 ($y$ as false)              | 7                           |
| 0                 | 0                     | 3                     | 3 ($y$ as false)              | 6                           |

Now. think about $m$ clauses that consistes an instance of the MAX E3SAT problem with $n$ varaibles.
We construct a MAX 2SAT instance by follow.

For each $j$th clause in MAX E3SAT problem, make 10 clauses with distinct auxiliary varaible in the algorithm above.
Then, set $l1$, $l2$, $l3$ as each literals used in $j$th clause.

For example, following MAX E3SAT was given.

1. $x_1 \lor x_2 \lor x_3$
2. $\overline{x_2} \lor x_4 \lor x_5$

Then, following is corresponding MAX 2SAT problem.

1.  $x_1$
2.  $x_2$
3.  $x_3$
4.  $\overline{x_1}\lor\overline{x_2}$
5.  $\overline{x_2}\lor\overline{x_3}$
6.  $\overline{x_1}\lor\overline{x_3}$
7.  $y_1$
8.  $x_1\lor\overline{y_1}$
9.  $x_2\lor\overline{y_1}$
10. $x_3\lor\overline{y_1}$
11. $\overline{x_2}$
12. $x_4$
13. $x_5$
14. $x_2\lor\overline{x_4}$
15. $\overline{x_4}\lor\overline{x_5}$
16. $x_2\lor\overline{x_5}$
17. $y_2$
18. $\overline{x_2}\lor\overline{y_2}$
19. $x_4\lor\overline{y_2}$
20. $x_5\lor\overline{y_2}$

Notice that if we make it so then, it shares the optimal solution because MAX 2SAT problem can satisfies 7 of clauses iff corresponding MAX E3SAT problem's clause satisfies and MAX 2SAT problem can satisfies 6 of clauses otherwise which is less than 7. 
For example, if $x_1$ is true and $x_4$ is true then, we can set some $y_1$ and $y_2$ to 14 of 20 becomes true.

Now, run the $\alpha$-approximation algorithm for MAX 2SAT on this instance.

Let's defnine some terminologies.

1. $k^{\star}$ be the number of satisfing clauses of MAX E3SAT instance from the optimal solution.
2. $\overline{k}$ be the number of satisfing clauses of MAX E3SAT instance from the $\alpha$-approximation algorithm's output of MAX 2SAT problem.

Notice that we may have some auxiliary variables $y$ but we will just ignore it for $\overline{k}$.

Then, MAX 2SAT instance's optimal soltuion satisfies $7k^{\star}$ $+$ $6(m - k^{\star})$ clauses.
Which means, $\alpha(7k^{\star}$ $+$ $6(m - k^{\star}))$ $\le$ $7\overline{k}$ $+$ $6(m - \overline{k})$.
Nocie that $0$ $&lt;$ $\alpha$ $\le$ $1$ because this is maximization problem.

As a result, following inequality is true.

$\alpha(7k^{\star}$ $+$ $6(m - k^{\star}))$ $\le$ $7\overline{k}$ $+$ $6(m - \overline{k})$ $\leftrightarrow$
$\alpha(k^{\star}$ $+$ $6m)$ $\le$ $\overline{k}$ $+$ $6m$ $\leftrightarrow$
$\alpha k^{\star}$ $+$ $\alpha 6m$ $\le$ $\overline{k}$ $+$ $6m$ $\leftrightarrow$
$\alpha k^{\star}$ $+$ $\alpha 6m$ $-$ $6m$ $\le$ $\overline{k}$ $\leftrightarrow$
$\alpha k^{\star}$ $+$ $6(\alpha  - 1)m$ $\le$ $\overline{k}$ $\leftrightarrow$
$\alpha k^{\star}$ $-$ $6(1 - \alpha)m$ $\le$ $\overline{k}$.

Now, we already have $\frac{7}{8}$-approximation algorithm.
Therefore, $k^{\star}$ $\ge$ $\frac{7}{8}m$ and $\frac{8}{7}k^{\star}$ $\ge$ $m$.

As a result, $\overline{k}$ $\ge$
$\alpha k^{\star}$ $-$ $6(1 - \alpha)m$ $\ge$
$\alpha k^{\star}$ $-$ $6(1 - \alpha)\frac{8}{7}k^{\star}$ $=$
$(\alpha - 6(1 - \alpha)\frac{8}{7})k^{\star}$ $=$
$(\frac{55}{7}\alpha - \frac{48}{7})k^{\star}$.

Notice that $m$ $\le$ $\frac{8}{7}k^{\star}$ $\leftrightarrow$
$-$ $\frac{8}{7}k^{\star}$ $\le$ $-$ $m$ $\leftrightarrow$
$-$ $6(1 - \alpha)\frac{8}{7}k^{\star}$ $\le$ $-$ $6(1 - \alpha)m$.

If there is $\alpha &gt; \frac{433}{440}$,
$\overline{k}$ $\ge$
$(\frac{55}{7}\alpha - \frac{48}{7})k^{\star}$ $&gt;$
$(\frac{55}{7}\frac{433}{440} - \frac{48}{7})k^{\star}$ $=$
$(\frac{7}{8})k^{\star}$.

Now, we show that such $\alpha$-approximation for MAX 2SAT can be used to give $(\frac{7}{8} + \epsilon)$-approximation algorithm for MAX-E3SAT problem for some constant $\epsilon &gt; 0$ and $\alpha &gt; \frac{433}{440}$.
Which is a contradiction.
Therefore, there is no such an approximation algorithm.</content><author><name>Programelot</name></author><summary type="html">MAX-E3SAT is a problem that finds a truth value assignment that satisfies the maximum number of clauses for a given a set of clause which contains exactly three literals.</summary></entry><entry><title type="html">Approximation algorithm(13) - Buy-at-bulk network design</title><link href="https://programelot.github.io/algorithm/approximation/2021/05/26/Approximation-algorithm(13)/" rel="alternate" type="text/html" title="Approximation algorithm(13) - Buy-at-bulk network design" /><published>2021-05-26T00:00:00+09:00</published><updated>2021-05-26T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/approximation/2021/05/26/Approximation%20algorithm(13)</id><content type="html" xml:base="https://programelot.github.io/algorithm/approximation/2021/05/26/Approximation-algorithm(13)/">In the real world, it is usually cheaper when you buy some thing in a bulk because of the delivery costs.
Now think about a undirected graph $G$ $=$ $(V,E)$ with length $l_e$ $\ge$ $0$ for all $e$ $\in$ $E$.
This problem requires $k$ pairs of vertices $(s_i,t_i)$ and demand $d_i$.
One thing that makes this problem interesting is that there is a cost function $f(u)$ such that satisfies following.

1. $f(0)$ $=$ $0$
2. $f$ is non-decreasing.
3. $f$ is subadditive which means $f(x + y)$ $\le$ $f(x)$ $+$ $f(y)$ for all $x, y$ $\in$ $\mathbb{N}$

Now problem asks to find $k$ paths from $s_i$ to $t_i$ with capacity $c:E \rightarrow \mathbb{N}$
to minimize $\sum\limits_{e \in E}f(c_e)l_e$
such that for any edge we can send $d_i$ units of commodity from $s_i$ to $t_i$ at the same time without violating $c$.

Notice that this algorithm can be solved in polynomial time if $G$ is a tree.
The reason is like follow.
If you think about any possible path on a tree, there is a unique path from $u$ to $v$ where $u,v$ $\in$ $V$.
Therefore, solution is just find a unique path and set the capacity and that's all.
Notice that this means it's not just in polynomial time but it gives a trivial unique solution.

Now, let's consider the following algorithm.

&lt;div class=&quot;algTab&quot;&gt;
    $\operatorname{for}$ each pair of vertices $u,v$ in $V$&lt;div class=&quot;algTab&quot;&gt;
        $P_{uv}$ be the shortest path from $u$ to $v$ in $E$
    &lt;/div&gt;
    $d_{uv}$ be the length of shortest path from $u$ to $v$.&lt;br&gt;
    Find a tree metric $(V',T)$ that approximates $d$&lt;br&gt;
    $\operatorname{for}$ each pair of vertices $u,v$ in $V$&lt;div class=&quot;algTab&quot;&gt;
        $P'_{uv}$ be the shortest path from $u$ to $v$ in $T$
    &lt;/div&gt;
    $c_e \leftarrow 0$ for all $e$ $\in$ $E$&lt;br&gt;
    $\operatorname{for}$ each pair $s_i, t_i$&lt;div class=&quot;algTab&quot;&gt;
        $\operatorname{for}$ each edge $(u,v)$ in $P'_{s_i t_i}$&lt;div class=&quot;algTab&quot;&gt;
            $\operatorname{for}$ each edge $e$ in $P_{u v}$&lt;div class=&quot;algTab&quot;&gt;
                Increase $c_e$ $\leftarrow$ $c_e$ $+$ $d_i$ 
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    return $c$
&lt;/div&gt;

First of all, we need to show that there is a tree metric.
Therefore we need to show that $d$ is a pseudometric.
Notice that most of properties are trivial but only triangular inequality need to be more detial.
Now, let's think about any path between $(x,y)$ and $(y,z)$.
Then, $d_{xy}$ $+$ $d_{yz}$ $=$
$\sum\limits_{e \in P_{xy}}l_e$ $+$ $\sum\limits_{e \in P_{yz}}l_e$ $=$
$\sum\limits_{e \in P_{xy} \cup P_{yz}}l_e$ $\ge$ 
$\sum\limits_{e \in P_{xz}}l_e$ $=$ 
$d_{xz}$.
Notice that concatinating path from $x$ to $y$ and path from $y$ to $z$ is a path from $x$ to $z$.
Which means at least longer or equal than &quot;shortest&quot; path from $x$ to $z$ in other world $P_{xy} \cup P_{yz}$ $\supseteq$ $P_{xz}$.

Now, problem is that we need to go through some $x$ that was not in $V$ but is in $V'$.
Therefore, we need to remove every such vertices.

Here is another algorithm that gives a tree metric from a tree metric.
&lt;div class=&quot;algTab&quot;&gt;
    $\operatorname{fit}$(V, V', T)&lt;div class=&quot;algTab&quot;&gt;
        $T' \leftarrow T$&lt;br&gt;
        $\operatorname{while}$ $\exists v \in V$ and $v$'s parent $w$ such that $w$ was not a left node of $T$&lt;div class=&quot;algTab&quot;&gt;
            Merge $v$ and $w$ to $v$
        &lt;/div&gt;
        Multiply the length of every edge of $T'$ by 4&lt;br&gt;
        return $(V, T')$
    &lt;/div&gt;
&lt;/div&gt;

If given a tree metric $T$ can be like follow.&lt;br&gt;
&lt;canvas id=&quot;canvas1&quot; width=&quot;200&quot; height=&quot;200&quot; style=&quot;border:1px solid #d3d3d3;&quot;&gt;
    Your browser does not support the HTML canvas tag.&lt;/canvas&gt;&lt;br&gt;
Then, other tree metric $T'$ can be like follow.&lt;br&gt;
&lt;canvas id=&quot;canvas2&quot; width=&quot;200&quot; height=&quot;200&quot; style=&quot;border:1px solid #d3d3d3;&quot;&gt;
    Your browser does not support the HTML canvas tag.&lt;/canvas&gt;&lt;br&gt;
&lt;script language = &quot;javascript&quot;&gt;
    c = document.getElementById(&quot;canvas1&quot;);
    ctx = c.getContext(&quot;2d&quot;);
    ctx.fillStyle = &quot;white&quot;;
    ctx.fillRect(0, 0, c.width, c.height);
  	ctx.beginPath();
    ctx.fillStyle = &quot;black&quot;;
  	ctx.moveTo(175, 170);
  	ctx.lineTo(125, 110);
  	ctx.lineTo(100, 40);
  	ctx.lineTo(75, 110);
  	ctx.lineTo(25, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(75, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(125, 170);
    ctx.stroke();
    ctx.fillStyle = &quot;white&quot;;
    ctx.beginPath();
    ctx.arc(25, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(175, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(100, 40, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.textAlign = &quot;center&quot;;
    ctx.fillStyle = &quot;red&quot;;
    ctx.font = &quot;15px Arial&quot;;
    ctx.fillText('4', 80, 80);
    ctx.fillText('4', 120, 80);
    ctx.fillText('2', 160, 140);
    ctx.fillText('2', 110, 140);
    ctx.fillText('2', 65, 145);
    ctx.fillText('2', 45, 140);
    ctx.fillText('{A,B,C,D}', 100, 40);
    ctx.fillText('{A,B,C}', 75, 110);
    ctx.fillText('{D}', 125, 110);
    ctx.fillText('{A}', 25, 170);
    ctx.fillText('{B}', 75, 170);
    ctx.fillText('{C}', 125, 170);
    ctx.fillText('{D}', 175, 170);
    c = document.getElementById(&quot;canvas2&quot;);
    ctx = c.getContext(&quot;2d&quot;);
    ctx.fillStyle = &quot;white&quot;;
    ctx.fillRect(0, 0, c.width, c.height);
  	ctx.beginPath();
    ctx.fillStyle = &quot;black&quot;;
  	ctx.moveTo(100, 40);
  	ctx.lineTo(75, 110);
  	ctx.lineTo(25, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(125, 170);
    ctx.stroke();
    ctx.fillStyle = &quot;white&quot;;
    ctx.beginPath();
    ctx.arc(25, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(100, 40, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.textAlign = &quot;center&quot;;
    ctx.fillStyle = &quot;red&quot;;
    ctx.font = &quot;15px Arial&quot;;
    ctx.fillText('16', 70, 80);
    ctx.fillText('8', 110, 140);
    ctx.fillText('8', 45, 140);
    ctx.fillText('{A}', 25, 170);
    ctx.fillText('{B}', 75, 110);
    ctx.fillText('{C}', 125, 170);
    ctx.fillText('{D}', 100, 40);
&lt;/script&gt;

Then, this algorithm returns a tree metric on $V$ such that $T_{uv}$ $\le$ 
$T'\_{uv}$ $\le$ 
$4T\_{uv}$ for all $u,v$ $\in$ $V$.
Notice that $T$ above is a result of original tree metric approximation algorithm.
Proof is like follow.

First, $T'\_{uv}$ $\le$ $T\_{uv}$ untill we multiply 4 because we only merge the vertices.
Therefore, $T'\_{uv}$ $\le$ $4T\_{uv}$ is true at the end of the algorithm.

Now, let's recap some facts from the tree metric $T$.

1. $\mathcal{L}_n$ is the level of the $n$. Notice that level of root node is $\log_2 \Delta$ and level of leaf node is $0$.
2. $\mathcal{A}_{uv}$ is the least common ancestor of $u$ and $v$.

Then, $T_{uv}$ $=$ 
$2\sum_{k=1}^{\mathcal{L}\_{\mathcal{A}\_{uv}}}2^k$ $=$ 
$2^{\mathcal{L}_{\mathcal{A}\_{uv}} + 2} - 4$ is true.

Now, let's think about the smallest possible length for $T'\_{uv}$.
Then, $u$ and $v$ will go only to the parent and the possible most go is right below $\mathcal{A}\_{uv}$.
One of $u$ and $v$ may be can be merged to $\mathcal{A}\_{uv}$ but not other one of $u$ and $v$ can be $\mathcal{A}\_{uv}$.
As a result, one of edge from $\mathcal{A}\_{uv}$ to child will still left to exist.
Therefore, $T'\_{uv}$ $\ge$
$4 \cdot 2^{\mathcal{L}\_{\mathcal{A}\_{uv}}}$ $=$ 
$2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 2}$ $\ge$
$2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 2} - 4$ $=$
$T_{uv}$
Therefore, claim holds.

Notice that this means $d_{uv}$ $\le$ $T_{uv}$ $\le$ $T'\_{uv}$ and $E[T'\_{uv}]$ $\le$ $E[4T_{uv}]$ $=$ $4E[T_{uv}]$ $\le$ $O(\ln \left\vert V \right\vert)d_{uv}$.
Therefore, $d_{uv}$ $\le$ $T'\_{uv}$ and $E[T'\_{uv}]$ $\le$ $O(\ln \left\vert V \right\vert)d_{uv}$.

Now, think about the algorithm follow.

&lt;div class=&quot;algTab&quot;&gt;
    $\operatorname{for}$ each pair of vertices $u,v$ in $V$&lt;div class=&quot;algTab&quot;&gt;
        $P_{uv}$ be the shortest path from $u$ to $v$ in $E$
    &lt;/div&gt;
    $d_{uv}$ be the length of shortest path from $u$ to $v$.&lt;br&gt;
    Find a tree metric $(V',T)$ that approximates $d$&lt;br&gt;
    $(V,T')$ $\leftarrow$ $\operatorname{fit}(V, V', T)$&lt;br&gt;
    $\operatorname{for}$ each pair of vertices $u,v$ in $V$&lt;div class=&quot;algTab&quot;&gt;
        $P'_{uv}$ be the shortest path from $u$ to $v$ in $T'$
    &lt;/div&gt;
    $c_e \leftarrow 0$ for all $e$ $\in$ $E$&lt;br&gt;
    $\operatorname{for}$ each pair $s_i, t_i$&lt;div class=&quot;algTab&quot;&gt;
        $\operatorname{for}$ each edge $(u,v)$ in $P'_{s_i t_i}$&lt;div class=&quot;algTab&quot;&gt;
            $\operatorname{for}$ each edge $e$ in $P_{u v}$&lt;div class=&quot;algTab&quot;&gt;
                Increase $c_e$ $\leftarrow$ $c_e$ $+$ $d_i$ 
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    return $c$
&lt;/div&gt;

Then this algorithm is a $O(\log n)$-approximation algorithm.
Proof is like follow.

Let's denote some terminologies.
1. $P^{\star}\_{u v}$ is the shortest path between $u$ and $v$ from the optimal solution.
2. $c^{\star}_e$ for $e$ $\in$ $E$ is the capacity of $e$ from the optimal solution.
3. $\operatorname{OPT}$ is the optimal solution; $\operatorname{OPT}$ $=$ 
$\sum\limits_{e \in E}f(\sum\limits_{i = 1 : e \in P^{\star}\_{s_i t_i}}^{k} d_i)l_e$ $=$ 
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1 : (u,v) \in P^{\star}\_{s_i t_i}}^{k} d_i)d\_{uv}$ $=$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}_{s_i t_i})) d\_{uv}$.
4. $P'\_{u v}$ is the unique shortest path between $u$ and $b$ from the $T'$.
5. $P^{S}\_{u v}$ is a path that changes each edge $(x,y)$ in $P^{\star}\_{u v}$ to $P'\_{x, y}$.
6. $\operatorname{OPT'}$ is the solution from $P^{S}\_{s_i t_i}$; $\operatorname{OPT'}$ $=$
$\sum\limits_{e \in T'}f(\sum\limits_{i = 1 : e \in P^{S}\_{s_i t_i}}^{k} d_i)l\_e$ $=$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}$.

Notice that $P^{S}\_{s_i t_i}$ may not be simple.
Then, $E[\operatorname{OPT'}]$ $=$
$E[\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}]$ $\le$
$E[\sum\limits_{(x,y) \in T'} \sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}]$ $=$
$E[\sum\limits_{(u,v) \in E} \sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}]$ $=$
$E[\sum\limits_{(u,v) \in E} \sum\limits_{(x,y) \in P'\_{u v}} f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i}))T'\_{xy}]$ $=$
$\sum\limits_{(u,v) \in E} E[ \sum\limits_{(x,y) \in P'\_{u v}} f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i}))T'\_{xy}]$ $=$
$\sum\limits_{(u,v) \in E} E[ f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) \sum\limits_{(x,y) \in P'\_{u v}}T'\_{xy}]$ $=$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) E[ \sum\limits_{(x,y) \in P'\_{u v}}T'\_{xy}]$ $=$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) E[T'\_{uv}]$ $\le$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) O(\ln \left\vert V \right\vert)d_{uv}$ $=$
$O(\ln \left\vert V \right\vert) \sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) d_{uv}$ $=$
$O(\ln \left\vert V \right\vert) \operatorname{OPT}$.

Notice that following facts.
First inequality holds because $f$ is subadditive.
Third equality holds because $P'\_{uv}$ $\in$ $T'$.
Sixth equality holds because $f(\sum\limits_{i = 1}^{k} d\_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i}))$ is independent from $u,v$.
Seventh equality holds because $\sum\limits_{(x,y) \in P'\_{u v}}T'\_{xy}$ is the distance from $u$ to $v$.
Therefore claim holds.

Simiallary, following is true.

Now let's denote $\operatorname{ALG}$ as the value of the output solution.
Then, $\operatorname{ALG}$ $=$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(x,y) \in T'} \mathbb{1}((x,y) \in P'\_{s_i t_i} \text{ and } (u,v) \in P\_{xy}))d\_{uv}$ $\le$
$\sum\limits_{(u,v) \in E} \sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i} \text{ and } (u,v) \in P\_{xy}))d\_{uv}$ $=$
$\sum\limits_{(x,y) \in T'} \sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i} \text{ and } (u,v) \in P\_{xy}))d\_{uv}$ $=$
$\sum\limits_{(x,y) \in T'} \sum\limits_{(u,v) \in P_{xy}} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i}))d\_{uv}$ $=$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i})) \sum\limits_{(u,v) \in P_{xy}}d\_{uv}$ $=$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i})) d\_{xy}$ $\le$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i})) T'\_{xy}$ $\le$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}$ $=$
$\operatorname{OPT'}$.

All eqaulities and inequalities except last ineuqality can be proven in the same way with above.
Therefore, we need to show only last inequality holds.

Proof for &quot;$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i})) T'\_{xy}$ $\le$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}$&quot; is like follow.

Let's think about &quot;$\mathbb{1}((x,y) \in P'\_{s_i t_i})$&quot; and 
&quot;$\sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v})$&quot; for some $x, y, i$.

Then first one is $1$ if $(x,y) \in P'\_{s_i t_i}$ and $0$ otherwise.
Therefore, there is nothing to show if $(x,y) \not\in P'\_{s_i t_i}$.
Now, let's assume that $(x,y) \in P'\_{s_i t_i}$.
Then, $P^{\star}\_{s_i t_i}$ should include at least $(s_i,t_i)$ or longer path from $s_i$ to $t_i$ for any $i$.
Which means the cardinarity of $\\{(u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}\\}$ should be bigger or equal than $1$.
Therefore, claim holds.
Notice that concatinating $(u,v) \in P^{\star}\_{s_i t_i}$ in $T'$ will be a valid path from $u$ to $v$.
Therefore, $(x,y)$ should be in some where in there.

As a result, $\operatorname{ALG}$ $\le$ $\operatorname{OPT'}$ $\le$ $O(\ln \left\vert V \right\vert) \operatorname{OPT}$.
Therefore claim holds.

Notice that algorithm runs in a polynomial time.</content><author><name>Programelot</name></author><summary type="html">In the real world, it is usually cheaper when you buy some thing in a bulk because of the delivery costs. Now think about a undirected graph $G$ $=$ $(V,E)$ with length $l_e$ $\ge$ $0$ for all $e$ $\in$ $E$. This problem requires $k$ pairs of vertices $(s_i,t_i)$ and demand $d_i$. One thing that makes this problem interesting is that there is a cost function $f(u)$ such that satisfies following.</summary></entry><entry><title type="html">Useful mathematical tools</title><link href="https://programelot.github.io/algorithm/approximation/2021/05/19/Useful-mathematical-tools/" rel="alternate" type="text/html" title="Useful mathematical tools" /><published>2021-05-19T00:00:00+09:00</published><updated>2021-05-19T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/approximation/2021/05/19/Useful%20mathematical%20tools</id><content type="html" xml:base="https://programelot.github.io/algorithm/approximation/2021/05/19/Useful-mathematical-tools/">1. $\ln n$ $\le$ $\sum\limits_{k = 1}^{n} \frac{1}{k}$ $\le$ $\ln n$ $+$ $1$ for $n$ $\in$ $\mathbb{Z}^{+}$
2. $\sum\limits_{k = 1}^{n}ar^{k-1}$ $=$ $a\frac{r^{n} - 1}{r - 1}$ if $r$ $\neq$ $1$, $n$ $\in$ $\mathbb{Z}$</content><author><name>Programelot</name></author><summary type="html">$\ln n$ $\le$ $\sum\limits_{k = 1}^{n} \frac{1}{k}$ $\le$ $\ln n$ $+$ $1$ for $n$ $\in$ $\mathbb{Z}^{+}$ $\sum\limits_{k = 1}^{n}ar^{k-1}$ $=$ $a\frac{r^{n} - 1}{r - 1}$ if $r$ $\neq$ $1$, $n$ $\in$ $\mathbb{Z}$</summary></entry><entry><title type="html">Approximation of metrics by tree metrics</title><link href="https://programelot.github.io/algorithm/approximation/2021/05/19/tree-metrics/" rel="alternate" type="text/html" title="Approximation of metrics by tree metrics" /><published>2021-05-19T00:00:00+09:00</published><updated>2021-05-19T00:00:00+09:00</updated><id>https://programelot.github.io/algorithm/approximation/2021/05/19/tree%20metrics</id><content type="html" xml:base="https://programelot.github.io/algorithm/approximation/2021/05/19/tree-metrics/">For a given vertices $V$ and distance $V \times V \rightarrow \mathcal{R} : d$.
$(V,d)$ is so called a metric if following properties are hold.

1. $d_{uv}$ $\ge$ $0$ for all $u,v$ $\in$ $V$
2. $d_{uv}$ $=$ $0$ iff $u = v$
3. $d_{uv}$ $=$ $d_{vu}$ for all $u,v$ $\in$ $V$
4. (Triangular inequality) $d_{uv}$ $\le$ $d_{uw}$ $+$ $d_{wv}$ for all $u,v,w$ $\in$ $V$

Notice that we say it is a pseudometric if property 2 changes to &quot;$d_{uv}$ $=$ $0$ if $u = v$&quot;.

A tree metic $(V', T)$ for a set of vertices $V$ is a tree $T$ defined on a set of nodes $V' \supseteq V$, whoese edges are given non negative lengths.
For $u,v$ $\in$ $V'$, let $T_{uv}$ denote the length of the unique path between $u$ and $v$ in $T$.

Notice that tree matrix is a matric.
It is trivial to be hold for 1 ~ 3.
For 4, if there is a path $u$ to $w$ and $w$ to $v$, then concatinating them is a path from $u$ to $v$.
It will have the length equal or less than sum of each path because there could be a cycle and it can be removed.

Given a metric $d$ on $V$, we say a tree metric $(V', T)$ is a $\operatorname{tree metic embedding}$ of distortion $\alpha$ if $d_{uv}$ $\le$ $T_{uv}$ $\le$ $\alpha d_{uv}$ for all $u,v$ $\in$ $V$.

However, do we even have any approximation for it in every time?
Yes, if we have gigantic distortion.
However, it's no with some distortion.
In fact it is known that there is no tree metric has distortion less than $\frac{n - 1}{8}$ for some metric $d$ on $n$ vertices.
However there is a good theorem.

Given a metric $d$ on $V$ such that $d_{uv}$ $\ge$ $1$ for all $u$ $\neq$ $v$, there exists a randomized algorithm that finds a tree metric $(V', T)$ such that for all $u, v$ $\in$ $V$, $d_{uv}$ $\le$ $T_{uv}$ and $E[T_{uv}]$ $\le$ $O(\ln \left\vert V \right\vert)d_{uv}$.
Notice that this randomized algorithm picks a tree metric from a given graph.
Proof is like follow.

Consider the following algorithm where $B(x, r)$ is a hypersphere with the center at $x$ and radius of $r$.
&lt;div class=&quot;algTab&quot;&gt;
    Pick $r_0$ $\in$ $[\frac{1}{2}, 1)$ uniformly at random&lt;br&gt;
    Choose $\Delta$ as the smallest power of two greater or equal than $2\max_{u,v \in V}d_{uv}$&lt;br&gt;
    Let $r_i$ $=$ $2^ir_0$ for $1$ $\le$ $i$ $\le$ $\log_2 \Delta$&lt;br&gt;
    Pick a permutation $\pi$ of $v$ uniformly at random&lt;br&gt;
    $\mathcal{C}(\log_2 \Delta) \leftarrow \{V\}$&lt;br&gt;
    Create a node corresponding to $V$ and make it the root node&lt;br&gt;
    $\operatorname{for}$ $i \leftarrow \log_2 \Delta, \log_2 \Delta - 1, \cdots, 1$&lt;div class=&quot;algTab&quot;&gt;
        $\mathcal{C}(i - 1) \leftarrow \emptyset$&lt;br&gt;
        $\operatorname{for}$ $C \in \mathcal{C}(i)$&lt;div class=&quot;algTab&quot;&gt;
            $S \leftarrow C$&lt;br&gt;
            $\operatorname{for}$ $j \leftarrow 1, 2, \cdots, \left\vert V \right\vert$&lt;div class=&quot;algTab&quot;&gt;
                $\operatorname{if}$ $B(\pi(j), r_{i-1})$ $\cap$ $S$ $\neq$ $\emptyset$&lt;div class=&quot;algTab&quot;&gt;
                    Add $\{B(\pi(j), r_{i-1}) \cap S\}$ to $\mathcal{C}(i -1)$&lt;br&gt;
                    $S$ $\leftarrow$ $S$ $-$ $(B(\pi(j), r_{i-1}) \cap S)$
                &lt;/div&gt;
            &lt;/div&gt;
            Create nodes corresponding to each set in $\mathcal{C}(i -1)$ and attach each node to the node in $\mathcal{C}(i)$ corresponding to its superset by an edge of length $2^i$
        &lt;/div&gt;
    &lt;/div&gt;
    $V' \leftarrow$ all nodes in $\bigcup\limits_{k = 0}^{\log_2 \Delta}\mathcal{C}(k)$&lt;br&gt;
    $T \leftarrow$ all edges between $\mathcal{C}(k)$ and $\mathcal{C}(k - 1)$ for all $1$ $\le$ $k$ $\le$ $\log_2 \Delta$&lt;br&gt;
    return $(V', T)$ 
&lt;/div&gt;

For an example, following graph's result will be like follow.

If given metric is like follow.&lt;br&gt;
&lt;canvas id=&quot;canvas1&quot; width=&quot;200&quot; height=&quot;200&quot; style=&quot;border:1px solid #d3d3d3;&quot;&gt;
    Your browser does not support the HTML canvas tag.&lt;/canvas&gt;&lt;br&gt;
Returned tree metric can be like follow.&lt;br&gt;
&lt;canvas id=&quot;canvas2&quot; width=&quot;200&quot; height=&quot;200&quot; style=&quot;border:1px solid #d3d3d3;&quot;&gt;
    Your browser does not support the HTML canvas tag.&lt;/canvas&gt;&lt;br&gt;
&lt;script language = &quot;javascript&quot;&gt;
    let c = document.getElementById(&quot;canvas1&quot;);
    let ctx = c.getContext(&quot;2d&quot;);
    ctx.fillStyle = &quot;white&quot;;
    ctx.fillRect(0, 0, c.width, c.height);
    ctx.fillStyle = &quot;white&quot;;
    ctx.beginPath();
    ctx.arc(100, 100, 80, 0, 2*Math.PI);
    ctx.stroke();
    ctx.beginPath();
    ctx.arc(100, 180, 10, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(100, 20, 10, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(20, 100, 10, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(180, 100, 10, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.textAlign = &quot;center&quot;;
    ctx.fillStyle = &quot;red&quot;;
    ctx.font = &quot;20px Arial&quot;;
    ctx.fillText('A', 100, 180);
    ctx.fillText('B', 100, 20);
    ctx.fillText('C', 20, 100);
    ctx.fillText('D', 180, 100);
    ctx.fillText('1', 44, 44);
    ctx.fillText('1', 156, 44);
    ctx.fillText('1', 44, 156);
    ctx.fillText('1', 156, 156);
    c = document.getElementById(&quot;canvas2&quot;);
    ctx = c.getContext(&quot;2d&quot;);
    ctx.fillStyle = &quot;white&quot;;
    ctx.fillRect(0, 0, c.width, c.height);
  	ctx.beginPath();
    ctx.fillStyle = &quot;black&quot;;
  	ctx.moveTo(175, 170);
  	ctx.lineTo(125, 110);
  	ctx.lineTo(100, 40);
  	ctx.lineTo(75, 110);
  	ctx.lineTo(25, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(75, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(125, 170);
    ctx.stroke();
    ctx.fillStyle = &quot;white&quot;;
    ctx.beginPath();
    ctx.arc(25, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(175, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(100, 40, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.textAlign = &quot;center&quot;;
    ctx.fillStyle = &quot;red&quot;;
    ctx.font = &quot;15px Arial&quot;;
    ctx.fillText('4', 80, 80);
    ctx.fillText('4', 120, 80);
    ctx.fillText('2', 160, 140);
    ctx.fillText('2', 110, 140);
    ctx.fillText('2', 65, 145);
    ctx.fillText('2', 45, 140);
    ctx.fillText('{A,B,C,D}', 100, 40);
    ctx.fillText('{A,B,C}', 75, 110);
    ctx.fillText('{D}', 125, 110);
    ctx.fillText('{A}', 25, 170);
    ctx.fillText('{B}', 75, 170);
    ctx.fillText('{C}', 125, 170);
    ctx.fillText('{D}', 175, 170);
&lt;/script&gt;

Now, following is true if we call the deepest nodes as level 0 and level $i$'s parent as level $i + 1$.
Note that each node at level 0 corresponding to a singleton and every vertex in $V$ appears exactly once.
The reason is that there can't be more than center itself because $r_0$ $&lt;$ $1$ $\le$ $d_{uv}$ for all $u,v$ $\in$ $V$.
Notice that every vertex at level $i$ is belongs to a hyper sphere of radius $r_i$ and centered by one of vertex in side of the set.
Which also means that level $\log_2 \Delta$ will contain entire $V$ because $r_{\log_2 \Delta}$ $=$ $2^{\log_2 \Delta} r_0$ $\ge$ $2^{\log_2 \Delta} \frac{1}{2}$ $=$ $\Delta \frac{1}{2}$ $\ge$ $2\max_{u,v \in V}d_{uv}\frac{1}{2}$ $=$ $\max_{u,v \in V}d_{uv}$.

Now, let's denote some terminologies for a node $n$ in the $(V', T)$.
1. $\mathcal{L}_n$ is the level of the $n$. Notice that level of root node is $\log_2 \Delta$ and level of leaf node is $0$.
2. $\mathcal{S}_n$ is the set of vertices which the corresponding hyper sphere includes.

Then, there are some facts.
1. $d_{yz}$ $\le$ $2r_{\mathcal{L}_n}$ for any $y,z$ $\in$ $\mathcal{S}_n$ becuase it should be in the same hyper sphere.
2. For any $u,v$ $\in$ $V$, they can't belongs to the same node at level $[\log_2 d_{uv}] - 1$ because otherwise $d_{uv}$ $\le$ $2r_{[\log_2 d_{uv}] - 1}$ $=$ $2 \cdot 2^{[\log_2 d_{uv}] - 1}r_0$ $=$ $2^{[\log_2 d_{uv}]}r_0$ $\le$ $2^{\log_2 d_{uv}}r_0$ $=$ $d_{uv}r_0$ $&lt;$ $d_{uv}$ which is a contradiction.

Then, $T_{uv}$ $\ge$ $d_{uv}$ is true.
Proof is like follow.
If $d_{uv}$ $&lt;$ $4$ then, $T_{uv}$ $\ge$ $d_{uv}$ because $T_{uv}$ $\ge$ $4$.
Notice that $T_{uv}$ $\ge$ $4$ is true because all edges in the $T$ is bigger or equal than $2$ and there should be at least one parent to go $v$ from $u$.
Now, other cases are $d_{uv}$ $\ge$ $4$.
Frist, $d_{uv}$ $\le$ $\sum\limits_{k = 0}^{[\log_2 d_{uv}]} 2^k$ because RHS is bigger than a binary representation of $d_{uv}$.
Then, $d_{uv}$ $\le$ $\sum\limits_{k = 0}^{[\log_2 d_{uv}]} 2^k$ $=$ $\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ $+$ $1$ $\le$ $\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ $+$ $\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ $=$ $2\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ $\le$ $T_{uv}$.
Notice that last inequality comes from the fact 2 above.
If we think about path from $u$ to $v$, it should go to at least level $[\log_2 d_{uv}]$ because it can't belongs to the same node untill level $[\log_2 d_{uv}] - 1$.
Also, $2\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ is a sum of length from $u$ to $v$ via level $[\log_2 d_{uv}]$.
Therefore, claim holds.

Now there are only one thing to show that $E[T_{uv}]$ $\le$ $O(\ln \left\vert V \right\vert)d_{uv}$.

To show this, there some terminologies to define.

1. $\mathcal{A}_{uv}$ is the least common ancestor of $u$ and $v$.
2. We say $w$ settles the pair of $u$ and $v$ on $i$ if $w$ is the first vertex in permutation $\pi$ such that at least one of $u$ and $v$ is in the hypersphere $B(w, r_i)$.
3. We say $w$ cut $u$ and $v$ on level $i$ if exactly one of $u$ and $v$ is in the hypersphere $B(w, r_i)$.
4. $X_{iw}(u,v)$ be the event that $w$ cuts $(u, v)$ on level $i$.
5. $S_{iW}(u,v)$ be the event that $w$ settles $(u, v)$ on level $i$.
6. $\mathbb{1}(x)$ is an indicator fuction such that $1$ if $x$ is true $0$ otherwise.

First, $T_{uv}$ $=$ 
$2\sum_{k=1}^{\mathcal{L}\_{\mathcal{A}\_{uv}}}2^k$ $=$ 
$2(2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 1} - 2)$ $=$ 
$2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 2} - 4$ $\le$ 
$2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 2}$.

Then, $T_{uv}$ $\le$ $\max\limits_{i = 0}^{\log_2 \Delta - 1} \mathbb{1}(\exists X_{iw}(u,v) \cap S_{iw}(u,v) \text{ for } w \in V) 2^{i + 3}$.

Notice that $\operatorname{argmax}\limits_{i = 0}^{\log_2 \Delta - 1} \mathbb{1}(\exists X_{iw}(u,v) \cap S_{iw}(u,v) \text{ for } w \in V)2^{i + 3}$ is the $\mathcal{A}_{uv}$.

Therefore, $T_{uv}$ $\le$ $\max\limits_{i = 0}^{\log_2 \Delta - 1} \mathbb{1}(\exists X_{iw}(u,v) \cap S_{iw}(u,v) \text{ for } w \in V) 2^{i + 3}$
$\le$ $\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} \mathbb{1}(\exists X_{iw}(u,v) \cap S_{iw}(u,v)) 2^{i + 3}$.

Now if we go back to the algorithm, there are two random events at the algorithm which are &quot;picking $r_0$&quot; and &quot;picking a random permutation $\pi$&quot;.
Therefore, we can average on certain path to select $T_{uv}$.
Then, $E[T_{uv}]$ $\le$ $\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v) \cap S_{iw}(u,v)] 2^{i + 3}$.
Notice that existance of $X_{iw}(u,v) \cap S_{iw}(u,v)$ for $w$ $\in$ $V$ on level $i$ will be depend on random varaibles and other things are indepedent with the random variable.

Now, let's consider followings.

With out loosing generality, let's assume that $d_{uw}$ $\le$ $d_{vw}$ for $w$ that cuts $u$ and $v$ on level $i$.
Then, $d_{uw}$ $\le$ $r_i$ $&lt;$ $d_{vw}$ because $u$ should be in $B(w, r_i)$ and $v$ shouldn't.
With above, we need to select $r_i$ uniformly at random with $2^ir_0$.
Then we will pick $r_i$ in $[2^{i-1},2^i)$ because we will pick $r_0$ in $[\frac{1}{2}, 1)$. 
Now, let's think about the $Pr[X_{iw}(u,v)]$.
Then, $Pr[X_{iw}(u,v)]$ $=$ $\frac{\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert}{\left\vert [2^{i-1}, 2^i \right\vert}$ $=$ $\frac{\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert}{2^{i-1}}$.
As a result, $\sum\limits_{i=0}^{\log_2 \Delta - 1}Pr[X_{iw}(u,v)]2^{i + 3}$ $=$ 
$\sum\limits_{i=0}^{\log_2 \Delta - 1}\frac{\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert}{2^{i-1}}2^{i + 3}$ $=$
$\sum\limits_{i=0}^{\log_2 \Delta - 1}\frac{2^{i + 3}}{2^{i-1}}\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert$ $=$
$2^4\sum\limits_{i=0}^{\log_2 \Delta - 1}\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert$ $=$
$16\sum\limits_{i=0}^{\log_2 \Delta - 1}\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert$ $=$
$16\left\vert [d_{uw}, d_{vw}) \right\vert$ for any $w$.
Notice that $\bigcup\limits_{i=0}^{\log_2 \Delta - 1}[2^{i-1}, 2^i)$ $=$ $[2^{-1}, 2^{\log_2 \Delta - 1})$ $=$ $[2^{-1}, 2^{-1}\Delta)$ $=$ $[2^{-1}, 2^{-1}2\max_{u,v \in V}d_{uv})$ $=$ $[2^{-1}, \max_{u,v \in V}d_{uv})$ $\supseteq$ set of possible $d_{uv}$ for all $u,v$ $\in$ $V$.
Which means it will see all possible area.
Notice that $d_{uv}$ $\ge$ $1$ and $Pr[X_{iw}(u,v)]$ means probability that $w$ on level $i$ will cut $u$ and $v$.
As a result, $Pr[X_{iw}(u,v)]$ $=$ $16\left\vert [d_{uw}, d_{vw}) \right\vert$ $=$ $16(d_{vw} - d{uw})$ $\le$ $16(d_{vu} + d_{uw} - d_{uw})$ $=$ $16d_{vu}$ $=$ $16d_{uv}$ from the triangular inequality.

Now, let's think about list $\mathbb{L}$ from $V$ such that sorted in the order $\min(d_{ux}, d_{vx})$ for $x$ $\in$ $\mathbb{L}$.
Now, think about 2 things.

1. Some $w$ $\in$ $V$ such that $w$ cuts $u$ and $v$.
2. Let's denote $w$'s level as $i$.
3. Let's denote $w$'s index in $\mathbb{L}$ is $\mathcal{I}_w$

Then, one of $u$ or $v$ should be in $B(z, r_i)$ for any $z$ that has less index than $\mathcal{I}\_w$.
Notice that $\min(d_{uz}, d_{vz})$ $\le$ $\min(d_{uw}, d_{vw})$ $\le$ $r_i$ because it is sorted by $\min(d_{ux}, d_{vx})$ and $w$ cuts $u$ and $v$.
Then, $Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $\le$ $\frac{1}{\mathcal{I}\_w}$ because $w$ need to be placed in $\pi$ more previous than all such $z$s.
Notice that there are at least $\mathcal{I}\_w$ candiadates that can cut $u$ and $v$ and $w$ need to be the first on $\pi$ to settle $u$ and $v$.
Moreover, $\sum\limits_{w \in V}Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $\le$ $\sum\limits_{w \in V}\frac{1}{\mathcal{I}\_w}$ for a fixed $i$.
Notice that if we fix $i$, $\mathcal{I}\_w$ will be some arbitrary order of vertices.
However that will be still fixed in some way after set-up random variables.
Which means $\sum\limits_{w \in V}Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $=$ $\sum\limits_{w \in V : \mathcal{I}\_w = k, w \text{ cuts } u \text{ and } v}\frac{1}{k}$ $=$ $\sum\limits_{k = 1 : \mathcal{I}\_w = k, w \text{ cuts } u \text{ and } v}^{\left\vert V \right\vert}\frac{1}{k}$ $\le$ $\sum\limits\_{k = 1}^{\left\vert V \right\vert}\frac{1}{k}$ $\le$ $\ln \left\vert V \right\vert$ $+$ $1$.
Finally, notice that $\mathcal{I}_w$ doesn't depend on $i$ because it only depend on $\min(d\_{ux}, d\_{vx})$.
Infact, it doesn't even depend on any random varaible.

Now, following 4 things are true for summary.
1. $E[T_{uv}]$ $\le$ $\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v) \cap S_{iw}(u,v)] 2^{i + 3}$
2. $\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v)]2^{i + 3}$ $\le$ $16d_{uv}$
3. $Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $\le$ $\frac{1}{\mathcal{I}\_w}$
4. $\sum\limits_{w \in V} \frac{1}{\mathcal{I}\_w}$ $\le$ $\ln \left\vert V \right\vert$ $+$ $1$

As a result, $E[T_{uv}]$ $\le$
$\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v) \cap S_{iw}(u,v)] 2^{i + 3}$ $=$
$\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]Pr[X_{iw}(u,v)] 2^{i + 3}$ $=$
$\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v)]2^{i + 3} Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $\le$
$\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v)]2^{i + 3}\frac{1}{\mathcal{I}\_w}$ $=$
$\sum\limits_{w \in V}\frac{1}{\mathcal{I}\_w}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v)]2^{i + 3}$ $\le$
$\sum\limits_{w \in V}\frac{1}{\mathcal{I}\_w}16d_{uv}$ $=$
$16d_{uv}\sum\limits_{w \in V} \frac{1}{\mathcal{I}\_w}$ $\le$
$16d{uv}(\ln \left\vert V \right\vert + 1)$ $=$ $O(\ln \left\vert V \right\vert)d_{uv}$.

Therefore, claim holds.</content><author><name>Programelot</name></author><summary type="html">For a given vertices $V$ and distance $V \times V \rightarrow \mathcal{R} : d$. $(V,d)$ is so called a metric if following properties are hold.</summary></entry></feed>