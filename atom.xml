<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="https://programelot.github.io/atom.xml" rel="self" type="application/atom+xml" /><link href="https://programelot.github.io/" rel="alternate" type="text/html" /><updated>2023-01-21T21:51:01+09:00</updated><id>https://programelot.github.io/atom.xml</id><title type="html">REAL</title><subtitle>I am Programelot who is researching about optimization.</subtitle><author><name>Programelot</name></author><entry><title type="html">Stack and queue</title><link href="https://programelot.github.io/2021/08/13/Stack-Queue/" rel="alternate" type="text/html" title="Stack and queue" /><published>2021-08-13T00:00:00+09:00</published><updated>2021-08-13T00:00:00+09:00</updated><id>https://programelot.github.io/2021/08/13/Stack%20Queue</id><content type="html" xml:base="https://programelot.github.io/2021/08/13/Stack-Queue/">There is another data strucutre that used to store tons of data.
Therefore, it has two special operations known as the insert and the pop.
However, there are two types of ways to make policies for inserting and poping a data from a structure.

Depending on this two method, it is so-called as a stack or a queue.
Stack has a property known as LIFO(Last-In-First-Out).
Queue has a property known as FIFO(First-In-First-Out).

## Stack ##
If we insert a data into a stack first, it should be popped from the stack first.
Therefore, it reserves the order we inserted even when it is popped.

## Queue ##
If we insert a data into a queue first, it should be popped from the stack later.
Therefore, it reverses the order we inserted even when it is popped.

## Complexity ##
If we use a list for implementing a stack and a queue, it is easy to get a good performance because we already has $O(1)$ complexity for inserting and deleting at the front and the end of the list.

| Time complexity  | Stack   | Queue   | 
| ---          | --- | --- | 
| Insert           | $O(1)$  | $O(1)$  |
| Pop              | $O(1)$  | $O(1)$  |
| Space complexity | $O(n)$  | $O(n)$  |</content><author><name>Programelot</name></author><category term="algorithm" /><summary type="html">There is another data strucutre that used to store tons of data. Therefore, it has two special operations known as the insert and the pop. However, there are two types of ways to make policies for inserting and poping a data from a structure.</summary></entry><entry><title type="html">Array and list</title><link href="https://programelot.github.io/2021/08/12/Array-List/" rel="alternate" type="text/html" title="Array and list" /><published>2021-08-12T00:00:00+09:00</published><updated>2021-08-12T00:00:00+09:00</updated><id>https://programelot.github.io/2021/08/12/Array%20List</id><content type="html" xml:base="https://programelot.github.io/2021/08/12/Array-List/">Before talking about algorithm itself, we need to talk about data structures that typically uses for algorithms.
Some of algorithms even works based on a specific data structure that optimizes the algorithm.
In this chapter, I'll explain the most common data structures only.

## Array ##

To store a number of data, there should be some data structure that can give a specific data you want anytime and store a data in to the storage either.
To acheive this property, there is the easiest data structure known as an array.
Like the name itself, it stores data in an array of storage.
Pros of this algorithm is that you can get a data anytime from an array in a constant time because all you need is an index.
In mathmatical format, it usually written as $a[0]$ or $a_0$.
However, there is a big disadvantange for this.
If you want to use an array, you need to know exact size of data you need.
Otherwise, you may can access to the data where you didn't meant to.
Therefore, it has a big disadvantage known as the fixed-size.
However, it can extend the array by making a new array and copy every element in side of the array.
Therefore, complexity of an array is like follow.

| Time complexity  | Array   |
| ---          | --- | 
| Search/Change    | $O(1)$  |
| Add (Front)      | $O(n)$  |
| Add (Random)     | $O(n)$  |
| Add (Back)       | $O(n)$  |
| Delete (Front)   | $O(n)$  |
| Delete (Random)  | $O(n)$  |
| Delete (Back)    | $O(n)$  |
| Merge            | $O(n)$  |
| Space complexity | $O(n)$  |

Notice that adding and delete will change the size of the array.
Merge means that merging two array into a single array.
It will be assumed to have the same size of two arrays.

## List 1 ##

To avoid this fixed-size problem, there is an alternative structure known as a list.
A list consists of nodes.
Each node has a data and a pointer to the next node.
Therefore, it can access to next node from any node.
However, it has a slow search algorithm because it can access only the next node.
Therefore, it takes a linear time to read an array.

| Time complexity  | List 1  |
| ---          | --- | 
| Search/Change    | $O(n)$  |
| Add (Front)      | $O(1)$  |
| Add (Random)     | $O(n)$  |
| Add (Back)       | $O(n)$  |
| Delete (Front)   | $O(1)$  |
| Delete (Random)  | $O(n)$  |
| Delete (Back)    | $O(n)$  |
| Merge            | $O(n)$  |
| Space complexity | $O(n)$  |

One other problem is that it can only add the new data without overhead at the front of the list.
Therefore, there is another ways to make a list.

## List 2 ##

What if we make a pointer to denotes the last point of the list at the same time?
It will gives an advantages that makes accessable at the end of the list.
Therefore, it will give better performance when it works for the end of the list.
At the same time, it has an advantage to merge two lists because it can connect the end point of a list to another list.

| Time complexity  | List 2  |
| ---          | --- | 
| Search/Change    | $O(n)$  |
| Add (Front)      | $O(1)$  |
| Add (Random)     | $O(n)$  |
| Add (Back)       | $O(1)$  |
| Delete (Front)   | $O(1)$  |
| Delete (Random)  | $O(n)$  |
| Delete (Back)    | $O(1)$  |
| Merge            | $O(1)$  |
| Space complexity | $O(n)$  |

However, it still has $O(n)$ complexity for read/change operation.
Therefore, it usually doesn't be used in actual implementation however the notation of the list is typically used for many other data structures.

## Vector ##

Last implementation is which standard c++ language uses.
It works like an ordinary array but it increases its size by double the size.
It gives a nice performance because it gives a constant complexity for adding and deleting data at the back of the array.
Notice that this is amortized analysis.
Therefore, it sometimes cause long term process.

| Time complexity  | Vector           |
| ---          | ---          | 
| Search/Change    | $O(1)$           |
| Add (Front)      | $O(n)$           |
| Add (Random)     | $O(n)$           |
| Add (Back)       | Amortized $O(1)$ |
| Delete (Front)   | $O(n)$           |
| Delete (Random)  | $O(n)$           |
| Delete (Back)    | Amortized $O(1)$ |
| Merge            | $O(n)$           |
| Space complexity | $O(n)$           |

## Comparison ##

| Time complexity  | Array   | List 1  | List 2  | Vector           |
| ---          | --- | --- | --- | ---          | 
| Search/Change    | $O(1)$  | $O(n)$  | $O(n)$  | $O(1)$           |
| Add (Front)      | $O(n)$  | $O(1)$  | $O(1)$  | $O(n)$           |
| Add (Random)     | $O(n)$  | $O(n)$  | $O(n)$  | $O(n)$           |
| Add (Back)       | $O(n)$  | $O(n)$  | $O(1)$  | Amortized $O(1)$ |
| Delete (Front)   | $O(n)$  | $O(1)$  | $O(1)$  | $O(n)$           |
| Delete (Random)  | $O(n)$  | $O(n)$  | $O(n)$  | $O(n)$           |
| Delete (Back)    | $O(n)$  | $O(n)$  | $O(1)$  | Amortized $O(1)$ |
| Merge            | $O(n)$  | $O(n)$  | $O(1)$  | $O(n)$           |
| Space complexity | $O(n)$  | $O(n)$  | $O(n)$  | $O(n)$           |</content><author><name>Programelot</name></author><category term="algorithm" /><summary type="html">Before talking about algorithm itself, we need to talk about data structures that typically uses for algorithms. Some of algorithms even works based on a specific data structure that optimizes the algorithm. In this chapter, I’ll explain the most common data structures only.</summary></entry><entry><title type="html">Complexity</title><link href="https://programelot.github.io/2021/08/10/Complexity/" rel="alternate" type="text/html" title="Complexity" /><published>2021-08-10T00:00:00+09:00</published><updated>2021-08-10T00:00:00+09:00</updated><id>https://programelot.github.io/2021/08/10/Complexity</id><content type="html" xml:base="https://programelot.github.io/2021/08/10/Complexity/">To analyze performances of algorithms, we need to define some jargons.

## Time complexity ##

The time complexity of an algorithm, $T(n)$ is a function that denotes running time of the algorithm depending on the size of input data.
For example, let's think about an algorithm that adds data with other data.
You may smart enough to add any arbitrary two number in 1 second.
Then, how many time will it took for 100 data?
It will be 100 seconds.
In this case, $T(n) = n$.

## Big O notation ##

Big O notation is the method to guarantee the upper bound of algorithms' perforamce.
For any time complexity $T(n)$, we say $T(n)$ $=$ $O(g(n))$ if there is some positive constant $M$,$x_0$ such that $T(n)$ $\le$ $M g(n)$ for all $x \ge x_0$.
For example, if $T(n)$ $=$ $n^3$ $+$ $10n^2$ $+$ $n$ $+$ $27$, $T(n)$ $=$ $O(n^3)$ for $M$ $=$ $39$, $x_0$ $=$ $1$.
Notice that $T(n)$ $=$ $n^3$ $+$ $10n^2$ $+$ $n$ $+$ $27$ $\le$ $n^3$ $+$ $10n^3$ $+$ $n^3$ $+$ $27n^3$ $=$ $39n^3$ for $n$ $\ge$ $1$.
In fact, it is enough to find the most steepest part in $T(n)$.

## Asymptotically approximate ##

In fact, it can be choosed to be worse than expected in big O notation.
For example, $T(n)$ $=$ $O(n^2)$ if $T(n)$ $=$ $O(n)$ in all cases.
Therefore, we say that &quot;An algorithm's time complexity asymptotically approximates to $g(n)$&quot; when $\lim\limits_{n \leftarrow \infty}\frac{T(n)}{Mg(n)} = 1$ for some positive constant $M$.

## Big $\Omega$ notation ##

Big $\Omega$ notation is the opposite with the big O notation.
It guarantess the lower bound of algorithms' performance.
For any time complexity $T(n)$, we say $T(n)$ $=$ $\Omega(g(n))$ if there is some positive constant $M$,$x_0$ such that $T(n)$ $\ge$ $M g(n)$ for all $x \ge x_0$.

## Big $\Theta$ notation ##

Big theta notation is used when an algorithm has the same complexity for both upper and lower bounds.
In other word, we say $T(n)$ $=$ $\Theta(g(n))$ if there is some positive constant $M1$,$M_2$,$x_0$ such that $M_2 g(n)$ $\le$ $T(n)$ $\le$ $M_1 g(n)$ for all $x \ge x_0$.
However, it is hard to expect that algorithm has such a complexity.
Some algorithms' performance vary between the data itself.
Therefore, some algorithm can't have big $\Theta$ notation for their time complexity.

## Amortized complexity ##

Amortized complexity is another measurement to analysis an algorithm.
Many algorithms doesn't have a nice $\Theta$ notation to explain the performance's performance.
It really depends on the situation.
However, it can be pessimistic to use only big O notation.
Therefore, amortized complexity measures a performance of an algorithm by dividing its complexity between executions.
If some algorithm works $O(1)$ for $n$ times and it works $O(n^2)$ for $1$ time.
Then, the amortized complexity of this algorithm is $O(\frac{1 \times n + n^2}{n + 1})$ $=$ $O(n)$.

## Space complexity ##

Space complexity is another measurable tool for algorithms.
It denotes how many memory spaces it uses.
We use all of notations above to represent space complexity either.</content><author><name>Programelot</name></author><category term="algorithm" /><summary type="html">To analyze performances of algorithms, we need to define some jargons.</summary></entry><entry><title type="html">Algorithm</title><link href="https://programelot.github.io/2021/08/02/Algorithm/" rel="alternate" type="text/html" title="Algorithm" /><published>2021-08-02T00:00:00+09:00</published><updated>2021-08-02T00:00:00+09:00</updated><id>https://programelot.github.io/2021/08/02/Algorithm</id><content type="html" xml:base="https://programelot.github.io/2021/08/02/Algorithm/">Algorithm is a mathmatical tool to solve some problem with propal methods.
For example, let's think about a situation follows.
Oneday, you've got a job from a city library.
However, there was a tournado yesterday so all books dropped out of the shelf.
Your employer calls you and asks you to clean it up in order of books' ID.
Despite of your low payment, you have no way but clean it up.
Therefore, you started to think about the way to clean it up.

## Insertion sort ##
You may give up to think about better way to clean it up.
Instead of it, you just started to clean it up by reading the ID of each book and put the book which has the smallest ID into the shelf.

## Quick sort ##
While you are doing such a thing, your friend decided to do the follow.
1. If there is only one book, just put it in with the revered direction.
2. If there is more than a book, select a book in random.
3. Put all books that have smaller ID than the book that you selected at 1 into the shelf.
4. Then add the book that you selected at 1 but in the reversed direction to identify this is the book which you used.
5. If all books are in the self with inverse direction, flip all books.
6. Otherwise, pick books between two reversed book and take books out of the shelf and do the same process from 1.

Notice that the starting point, end point of the shelf will be considered as the reversed book in 6.

This looks more complex but it usually takes much less time than you did.
See the example below.

## Example ##
For example, there are books that have IDs of 52,33,25,19,28,38,37,45,73,68,61,69,87,78,90.
Now, let's follow the each process.

You will clean the book like bellow.
Notice that I marked [] as books that shelf has, {} as what you are memorizing and () as what you are looking.
In this algorithm, you can see only one book at once because numbers are too complex to see it on glance.
At the same time, you can memorize a number at most because of its long digits.

1. (52), 33, 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
2. {52}, (33), 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
3. 52, {33}, (25), 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
4. 52, 33, {25}, (19), 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
5. 52, 33, 25, {19}, (28), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
6. 52, 33, 25, {19}, 28, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
7. 52, 33, 25, {19}, 28, 38, (37), 45, 73, 68, 61, 69, 87, 78, 90
8. 52, 33, 25, {19}, 28, 38, 37, (45), 73, 68, 61, 69, 87, 78, 90
9. 52, 33, 25, {19}, 28, 38, 37, 45, (73), 68, 61, 69, 87, 78, 90
10. 52, 33, 25, {19}, 28, 38, 37, 45, 73, (68), 61, 69, 87, 78, 90
11. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, (61), 69, 87, 78, 90
12. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, 61, (69), 87, 78, 90
13. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, 61, 69, (87), 78, 90
14. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, 61, 69, 87, (78), 90
15. 52, 33, 25, {19}, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, (90)
16. [19], 52, 33, 25, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
17. [19], (52), 33, 25, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
18. [19], {52}, (33), 25, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
19. [19], 52, {33}, (25), 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
20. [19], 52, 33, {25}, (28), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
21. [19], 52, 33, {25}, 28, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
22. [19], 52, 33, {25}, 28, 38, (37), 45, 73, 68, 61, 69, 87, 78, 90
23. [19], 52, 33, {25}, 28, 38, 37, (45), 73, 68, 61, 69, 87, 78, 90
24. [19], 52, 33, {25}, 28, 38, 37, 45, (73), 68, 61, 69, 87, 78, 90
25. [19], 52, 33, {25}, 28, 38, 37, 45, 73, (68), 61, 69, 87, 78, 90
26. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, (61), 69, 87, 78, 90
27. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, 61, (69), 87, 78, 90
28. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, 61, 69, (87), 78, 90
29. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, 61, 69, 87, (78), 90
30. [19], 52, 33, {25}, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, (90)
31. [19, 25], 52, 33, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
32. [19, 25], (52), 33, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
33. [19, 25], {52}, (33), 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
34. [19, 25], 52, {33}, (28), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
35. [19, 25], 52, 33, {28}, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
36. [19, 25], 52, 33, {28}, 38, (37), 45, 73, 68, 61, 69, 87, 78, 90
37. [19, 25], 52, 33, {28}, 38, 37, (45), 73, 68, 61, 69, 87, 78, 90
38. [19, 25], 52, 33, {28}, 38, 37, 45, (73), 68, 61, 69, 87, 78, 90
39. [19, 25], 52, 33, {28}, 38, 37, 45, 73, (68), 61, 69, 87, 78, 90
40. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, (61), 69, 87, 78, 90
41. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, 61, (69), 87, 78, 90
42. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, 61, 69, (87), 78, 90
43. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, 61, 69, 87, (78), 90
44. [19, 25], 52, 33, {28}, 38, 37, 45, 73, 68, 61, 69, 87, 78, (90)
45. [19, 25, 28], 52, 33, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
46. [19, 25, 28], (52), 33, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
47. [19, 25, 28], {52}, (33), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
48. [19, 25, 28], 52, {33}, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
49. [19, 25, 28], 52, {33}, 38, (37), 45, 73, 68, 61, 69, 87, 78, 90
50. [19, 25, 28], 52, {33}, 38, 37, (45), 73, 68, 61, 69, 87, 78, 90
51. [19, 25, 28], 52, {33}, 38, 37, 45, (73), 68, 61, 69, 87, 78, 90
52. [19, 25, 28], 52, {33}, 38, 37, 45, 73, (68), 61, 69, 87, 78, 90
53. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, (61), 69, 87, 78, 90
54. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, 61, (69), 87, 78, 90
55. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, 61, 69, (87), 78, 90
56. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, 61, 69, 87, (78), 90
57. [19, 25, 28], 52, {33}, 38, 37, 45, 73, 68, 61, 69, 87, 78, (90)
58. [19, 25, 28, 33], 52, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
59. [19, 25, 28, 33], (52), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
60. [19, 25, 28, 33], {52}, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
61. [19, 25, 28, 33], 52, {38}, (37), 45, 73, 68, 61, 69, 87, 78, 90
62. [19, 25, 28, 33], 52, 38, {37}, (45), 73, 68, 61, 69, 87, 78, 90
63. [19, 25, 28, 33], 52, 38, {37}, 45, (73), 68, 61, 69, 87, 78, 90
64. [19, 25, 28, 33], 52, 38, {37}, 45, 73, (68), 61, 69, 87, 78, 90
65. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, (61), 69, 87, 78, 90
66. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, 61, (69), 87, 78, 90
67. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, 61, 69, (87), 78, 90
68. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, 61, 69, 87, (78), 90
69. [19, 25, 28, 33], 52, 38, {37}, 45, 73, 68, 61, 69, 87, 78, (90)
70. [19, 25, 28, 33, 37], 52, 38, 45, 73, 68, 61, 69, 87, 78, 90
71. [19, 25, 28, 33, 37], (52), 38, 45, 73, 68, 61, 69, 87, 78, 90
72. [19, 25, 28, 33, 37], {52}, (38), 45, 73, 68, 61, 69, 87, 78, 90
73. [19, 25, 28, 33, 37], 52, {38}, (45), 73, 68, 61, 69, 87, 78, 90
74. [19, 25, 28, 33, 37], 52, {38}, 45, (73), 68, 61, 69, 87, 78, 90
75. [19, 25, 28, 33, 37], 52, {38}, 45, 73, (68), 61, 69, 87, 78, 90
76. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, (61), 69, 87, 78, 90
77. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, 61, (69), 87, 78, 90
78. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, 61, 69, (87), 78, 90
79. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, 61, 69, 87, (78), 90
80. [19, 25, 28, 33, 37], 52, {38}, 45, 73, 68, 61, 69, 87, 78, (90)
81. [19, 25, 28, 33, 37, 38], 52, 45, 73, 68, 61, 69, 87, 78, 90
82. [19, 25, 28, 33, 37, 38], (52), 45, 73, 68, 61, 69, 87, 78, 90
83. [19, 25, 28, 33, 37, 38], {52}, (45), 73, 68, 61, 69, 87, 78, 90
84. [19, 25, 28, 33, 37, 38], 52, {45}, (73), 68, 61, 69, 87, 78, 90
85. [19, 25, 28, 33, 37, 38], 52, {45}, 73, (68), 61, 69, 87, 78, 90
86. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, (61), 69, 87, 78, 90
87. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, 61, (69), 87, 78, 90
88. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, 61, 69, (87), 78, 90
89. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, 61, 69, 87, (78), 90
90. [19, 25, 28, 33, 37, 38], 52, {45}, 73, 68, 61, 69, 87, 78, (90)
91. [19, 25, 28, 33, 37, 38, 45], 52, 73, 68, 61, 69, 87, 78, 90
92. [19, 25, 28, 33, 37, 38, 45], (52), 73, 68, 61, 69, 87, 78, 90
93. [19, 25, 28, 33, 37, 38, 45], {52}, (73), 68, 61, 69, 87, 78, 90
94. [19, 25, 28, 33, 37, 38, 45], {52}, 73, (68), 61, 69, 87, 78, 90
95. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, (61), 69, 87, 78, 90
96. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, 61, (69), 87, 78, 90
97. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, 61, 69, (87), 78, 90
98. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, 61, 69, 87, (78), 90
99. [19, 25, 28, 33, 37, 38, 45], {52}, 73, 68, 61, 69, 87, 78, (90)
100. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, 61, 69, 87, 78, 90
101. [19, 25, 28, 33, 37, 38, 45, 52], (73), 68, 61, 69, 87, 78, 90
102. [19, 25, 28, 33, 37, 38, 45, 52], {73}, (68), 61, 69, 87, 78, 90
103. [19, 25, 28, 33, 37, 38, 45, 52], 73, {68}, (61), 69, 87, 78, 90
104. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, {61}, (69), 87, 78, 90
105. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, {61}, 69, (87), 78, 90
106. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, {61}, 69, 87, (78), 90
107. [19, 25, 28, 33, 37, 38, 45, 52], 73, 68, {61}, 69, 87, 78, (90)
108. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, 68, 69, 87, 78, 90
109. [19, 25, 28, 33, 37, 38, 45, 52, 61], (73), 68, 69, 87, 78, 90
110. [19, 25, 28, 33, 37, 38, 45, 52, 61], {73}, (68), 69, 87, 78, 90
111. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, {68}, (69), 87, 78, 90
112. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, {68}, 69, (87), 78, 90
113. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, {68}, 69, 87, (78), 90
114. [19, 25, 28, 33, 37, 38, 45, 52, 61], 73, {68}, 69, 87, 78, (90)
115. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], 73, 69, 87, 78, 90
116. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], (73), 69, 87, 78, 90
117. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], {73}, (69), 87, 78, 90
118. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], 73, {69}, (87), 78, 90
119. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], 73, {69}, 87, (78), 90
120. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68], 73, {69}, 87, 78, (90)
121. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], 73, 87, 78, 90
122. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], (73), 87, 78, 90
123. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], {73}, (87), 78, 90
124. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], {73}, 87, (78), 90
125. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69], {73}, 87, 78, (90)
126. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73], 87, 78, 90
127. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73], (87), 78, 90
128. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73], {87}, (78), 90
129. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73], 87, {78}, (90)
130. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78], 87, 90
131. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78], (87), 90
132. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78], {87}, (90)
133. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87], 90
134. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87], (90)
135. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87, 90]

As a result, it takes 135 steps.
However, your friend can get a result like below.
Notice that I marked revered book by !.


1. (52), 33, 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
2. {52}, (33), 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
3. [33], {52}, 25, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
4. [33], {52}, (25), 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
5. [33, 25], {52}, 19, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
6. [33, 25], {52}, (19), 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
7. [33, 25, 19], {52}, 28, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
8. [33, 25, 19], {52}, (28), 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
9. [33, 25, 19, 28], {52}, 38, 37, 45, 73, 68, 61, 69, 87, 78, 90
10. [33, 25, 19, 28], {52}, (38), 37, 45, 73, 68, 61, 69, 87, 78, 90
11. [33, 25, 19, 28, 38], {52}, 37, 45, 73, 68, 61, 69, 87, 78, 90
12. [33, 25, 19, 28, 38], {52}, (37), 45, 73, 68, 61, 69, 87, 78, 90
13. [33, 25, 19, 28, 38, 37], {52}, 45, 73, 68, 61, 69, 87, 78, 90
14. [33, 25, 19, 28, 38, 37], {52}, (45), 73, 68, 61, 69, 87, 78, 90
15. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, 69, 87, 78, 90
16. [33, 25, 19, 28, 38, 37, 45], {52}, (73), 68, 61, 69, 87, 78, 90
17. [33, 25, 19, 28, 38, 37, 45], {52}, 73, (68), 61, 69, 87, 78, 90
18. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, (61), 69, 87, 78, 90
19. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, (69), 87, 78, 90
20. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, 69, (87), 78, 90
21. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, 69, 87, (78), 90
22. [33, 25, 19, 28, 38, 37, 45], {52}, 73, 68, 61, 69, 87, 78, (90)
23. [33, 25, 19, 28, 38, 37, 45, !52!], 73, 68, 61, 69, 87, 78, 90
24. [33, 25, 19, 28, 38, 37, 45, !52!], (73), 68, 61, 69, 87, 78, 90
25. [33, 25, 19, 28, 38, 37, 45, !52!], {73}, (68), 61, 69, 87, 78, 90
26. [33, 25, 19, 28, 38, 37, 45, !52!, 68], {73}, 61, 69, 87, 78, 90
27. [33, 25, 19, 28, 38, 37, 45, !52!, 68], {73}, (61), 69, 87, 78, 90
28. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61], {73}, 69, 87, 78, 90
29. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61], {73}, (69), 87, 78, 90
30. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69], {73}, 87, 78, 90
31. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69], {73}, (87), 78, 90
32. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69], {73}, 87, (78), 90
33. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69], {73}, 87, 78, (90)
34. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!], 87, 78, 90
35. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!], (87), 78, 90
36. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!], {87}, (78), 90
37. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78], {87}, 90
38. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78], {87}, (90)
39. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78, !87!], 90
40. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78, !87!], (90)
41. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61, 69, !73!, 78, !87!, !90!]
42. [33, 25, 19, 28, 38, 37, 45, !52!, 68, 61], 69, [!73!, 78, !87!, !90!]
43. [33, 25, 19, 28, 38, 37, 45, !52!, 68], 61, 69, [!73!, 78, !87!, !90!]
44. [33, 25, 19, 28, 38, 37, 45, !52!], 68, 61, 69, [!73!, 78, !87!, !90!]
45. [33, 25, 19, 28, 38, 37, 45, !52!], (68), 61, 69, [!73!, 78, !87!, !90!]
46. [33, 25, 19, 28, 38, 37, 45, !52!], {68}, (61), 69, [!73!, 78, !87!, !90!]
47. [33, 25, 19, 28, 38, 37, 45, !52!, 61], {68}, 69, [!73!, 78, !87!, !90!]
48. [33, 25, 19, 28, 38, 37, 45, !52!, 61], {68}, (69), [!73!, 78, !87!, !90!]
49. [33, 25, 19, 28, 38, 37, 45, !52!, 61, !68!], 69, [!73!, 78, !87!, !90!]
50. [33, 25, 19, 28, 38, 37, 45, !52!, 61, !68!], (69), [!73!, 78, !87!, !90!]
51. [33, 25, 19, 28, 38, 37, 45, !52!, 61, !68!, !69!, !73!, 78, !87!, !90!]
52. [33, 25, 19, 28, 38, 37, 45, !52!], 61, [!68!, !69!, !73!, 78, !87!, !90!]
53. [33, 25, 19, 28, 38, 37, 45, !52!], (61), [!68!, !69!, !73!, 78, !87!, !90!]
54. [33, 25, 19, 28, 38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
55. 33, [25, 19, 28, 38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
56. 33, 25, [19, 28, 38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
57. 33, 25, 19, [28, 38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
58. 33, 25, 19, 28, [38, 37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
59. 33, 25, 19, 28, 38, [37, 45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
60. 33, 25, 19, 28, 38, 37, [45, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
61. 33, 25, 19, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
62. (33), 25, 19, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
63. {33}, (25), 19, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
64. [25], {33}, 19, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
65. [25], {33}, (19), 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
66. [25, 19], {33}, 28, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
67. [25, 19], {33}, (28), 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
68. [25, 19, 28], {33}, 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
69. [25, 19, 28], {33}, (38), 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
70. [25, 19, 28], {33}, 38, (37), 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
71. [25, 19, 28], {33}, 38, 37, (45), [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
72. [25, 19, 28, !33!], 38, 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
73. [25, 19, 28, !33!], (38), 37, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
74. [25, 19, 28, !33!], {38}, (37), 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
75. [25, 19, 28, !33!, 37], {38}, 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
76. [25, 19, 28, !33!, 37], {38}, (45), [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
77. [25, 19, 28, !33!, 37, !38!], 45, [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
78. [25, 19, 28, !33!, 37, !38!], (45), [!52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
79. [25, 19, 28, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
80. 25, [19, 28, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
81. 25, 19, [28, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
82. 25, 19, 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
83. (25), 19, 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
84. {25}, (19), 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
85. [19], {25}, 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
86. [19], {25}, (28), [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
87. [19, !25!], 28, [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
88. [19, !25!], (28), [!33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
89. [19, !25!, !28!, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
90. 19, [!25!, !28!, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
91. (19), [!25!, !28!, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
92. [!19!, !25!, !28!, !33!, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
93. [!19!, !25!, !28!, !33!], 37, [!38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
94. [!19!, !25!, !28!, !33!], (37), [!38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
95. [!19!, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, 78, !87!, !90!]
96. [!19!, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!], 78, [!87!, !90!]
97. [!19!, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!], (78), [!87!, !90!]
98. [!19!, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
99. [19, !25!, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
100. [19, 25, !28!, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
101. [19, 25, 28, !33!, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
102. [19, 25, 28, 33, !37!, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
103. [19, 25, 28, 33, 37, !38!, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
104. [19, 25, 28, 33, 37, 38, !45!, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
105. [19, 25, 28, 33, 37, 38, 45, !52!, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
106. [19, 25, 28, 33, 37, 38, 45, 52, !61!, !68!, !69!, !73!, !78!, !87!, !90!]
107. [19, 25, 28, 33, 37, 38, 45, 52, 61, !68!, !69!, !73!, !78!, !87!, !90!]
108. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, !69!, !73!, !78!, !87!, !90!]
109. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, !73!, !78!, !87!, !90!]
110. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, !78!, !87!, !90!]
111. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, !87!, !90!]
112. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87, !90!]
113. [19, 25, 28, 33, 37, 38, 45, 52, 61, 68, 69, 73, 78, 87, 90]

As a result, your friend can get a result in 113 step.
Which means 19% faster than you are.

To solve this problem, we call both methods as sorting algorithms.
However, it shows different perforamce as you can see.
From the next time, it will focused on the performance of the algorithm and comparison between them.</content><author><name>Programelot</name></author><category term="algorithm" /><summary type="html">Algorithm is a mathmatical tool to solve some problem with propal methods. For example, let’s think about a situation follows. Oneday, you’ve got a job from a city library. However, there was a tournado yesterday so all books dropped out of the shelf. Your employer calls you and asks you to clean it up in order of books’ ID. Despite of your low payment, you have no way but clean it up. Therefore, you started to think about the way to clean it up.</summary></entry><entry><title type="html">Hardness of approximation</title><link href="https://programelot.github.io/2021/05/28/Hardness-of-approximation/" rel="alternate" type="text/html" title="Hardness of approximation" /><published>2021-05-28T00:00:00+09:00</published><updated>2021-05-28T00:00:00+09:00</updated><id>https://programelot.github.io/2021/05/28/Hardness%20of%20approximation</id><content type="html" xml:base="https://programelot.github.io/2021/05/28/Hardness-of-approximation/">MAX-E3SAT is a problem that finds a truth value assignment that satisfies the maximum number of clauses for a given a set of clause which contains exactly three literals.

MAX-2SAT is a problem that finds a truth value assignment that satisfies the maximum number of clauses for a given a set of clauses which contains at most two literals.

Then there exists a $\frac{7}{8}$-approximation algorithm for MAX-E3SAT problem.

Proof is like follow.
If you see all of the clauses and count the existance of each literals and complementary of literals.
Then, we can pick at least half of them to be satisfied by pick $x_i$ or $\overline{x_i}$.
Then, we can cover at least $\frac{7}{8}$ of them because we have three literals for one clauses.

Then, P=NP if there exists a $(\frac{7}{8} + \epsilon)$-approximation algorithm for MAX-E3SAT problem for all constant $\epsilon &gt; 0$.

Proof will be updated later.

Then there exists no $\alpha$-approximation for MAX 2SAT for any constant $\alpha &gt; \frac{433}{440}$ unless P=NP.

Proof is like follow.

First of all, let's think about follow.

For three literals $l1$, $l2$ and $l3$, consider the follwing set of ten clauses in terms of $l1, l2, l3$ and auxiliary variable $y$.

1.  $l1$
2.  $l2$
3.  $l3$
4.  $\overline{l1}\lor\overline{l2}$
5.  $\overline{l2}\lor\overline{l3}$
6.  $\overline{l1}\lor\overline{l3}$
7.  $y$
8.  $l1\lor\overline{y}$
9.  $l2\lor\overline{y}$
10. $l3\lor\overline{y}$

If $l1 \lor l2 \lor l3$ is satisfied, we can choose the value of $y$ so that exactly seven of the ten clauses are satisfied and it is impossible to satisfy more than that.
If $l1 \lor l2 \lor l3$ is not satisfied, we can choose the value of $y$ so that exactly six of the ten clauses are satisfied and it is impossible to satisfy more than that.

Notice that we can have following table with number of satisfied clauses if $y$ is true.

| # true literals   | # true clauses in 1~3   | # true clauses in 4~6   | # true clauses in 7~10          | # true clauses in Total       |
| ---           | ---               | ---               | ---                       | ---                     |
| 3                 | 3                     | 0                     | 4                             | 7                           |
| 2                 | 2                     | 2                     | 3                             | 7                           |
| 1                 | 1                     | 3                     | 2                             | 6                           |
| 0                 | 0                     | 3                     | 1                             | 4                           |

If $y$ is false then number of satisfied clauses is like below.

| # true literals   | # true clauses in 1~3   | # true clauses in 4~6   | # true clauses in 7~10          | # true clauses in Total       |
| ---           | ---               | ---               | ---                       | ---                     |
| 3                 | 3                     | 0                     | 3                             | 6                           |
| 2                 | 2                     | 2                     | 3                             | 7                           |
| 1                 | 1                     | 3                     | 3                             | 7                           |
| 0                 | 0                     | 3                     | 3                             | 6                           |

As a result, maximum is follow.

| # true literals   | # true clauses in 1~3   | # true clauses in 4~6   | # true clauses in 7~10 (best)   | # true clauses in Total(best) |
| ---           | ---               | ---               | ---                       | ---                     |
| 3                 | 3                     | 0                     | 4 ($y$ as true)               | 7                           |
| 2                 | 2                     | 2                     | 3 ($y$ as true/false)         | 7                           |
| 1                 | 1                     | 3                     | 3 ($y$ as false)              | 7                           |
| 0                 | 0                     | 3                     | 3 ($y$ as false)              | 6                           |

Now. think about $m$ clauses that consistes an instance of the MAX E3SAT problem with $n$ varaibles.
We construct a MAX 2SAT instance by follow.

For each $j$th clause in MAX E3SAT problem, make 10 clauses with distinct auxiliary varaible in the algorithm above.
Then, set $l1$, $l2$, $l3$ as each literals used in $j$th clause.

For example, following MAX E3SAT was given.

1. $x_1 \lor x_2 \lor x_3$
2. $\overline{x_2} \lor x_4 \lor x_5$

Then, following is corresponding MAX 2SAT problem.

1.  $x_1$
2.  $x_2$
3.  $x_3$
4.  $\overline{x_1}\lor\overline{x_2}$
5.  $\overline{x_2}\lor\overline{x_3}$
6.  $\overline{x_1}\lor\overline{x_3}$
7.  $y_1$
8.  $x_1\lor\overline{y_1}$
9.  $x_2\lor\overline{y_1}$
10. $x_3\lor\overline{y_1}$
11. $\overline{x_2}$
12. $x_4$
13. $x_5$
14. $x_2\lor\overline{x_4}$
15. $\overline{x_4}\lor\overline{x_5}$
16. $x_2\lor\overline{x_5}$
17. $y_2$
18. $\overline{x_2}\lor\overline{y_2}$
19. $x_4\lor\overline{y_2}$
20. $x_5\lor\overline{y_2}$

Notice that if we make it so then, it shares the optimal solution because MAX 2SAT problem can satisfies 7 of clauses iff corresponding MAX E3SAT problem's clause satisfies and MAX 2SAT problem can satisfies 6 of clauses otherwise which is less than 7. 
For example, if $x_1$ is true and $x_4$ is true then, we can set some $y_1$ and $y_2$ to 14 of 20 becomes true.

Now, run the $\alpha$-approximation algorithm for MAX 2SAT on this instance.

Let's defnine some terminologies.

1. $k^{\star}$ be the number of satisfing clauses of MAX E3SAT instance from the optimal solution.
2. $\overline{k}$ be the number of satisfing clauses of MAX E3SAT instance from the $\alpha$-approximation algorithm's output of MAX 2SAT problem.

Notice that we may have some auxiliary variables $y$ but we will just ignore it for $\overline{k}$.

Then, MAX 2SAT instance's optimal soltuion satisfies $7k^{\star}$ $+$ $6(m - k^{\star})$ clauses.
Which means, $\alpha(7k^{\star}$ $+$ $6(m - k^{\star}))$ $\le$ $7\overline{k}$ $+$ $6(m - \overline{k})$.
Nocie that $0$ $&lt;$ $\alpha$ $\le$ $1$ because this is maximization problem.

As a result, following inequality is true.

$\alpha(7k^{\star}$ $+$ $6(m - k^{\star}))$ $\le$ $7\overline{k}$ $+$ $6(m - \overline{k})$ $\leftrightarrow$
$\alpha(k^{\star}$ $+$ $6m)$ $\le$ $\overline{k}$ $+$ $6m$ $\leftrightarrow$
$\alpha k^{\star}$ $+$ $\alpha 6m$ $\le$ $\overline{k}$ $+$ $6m$ $\leftrightarrow$
$\alpha k^{\star}$ $+$ $\alpha 6m$ $-$ $6m$ $\le$ $\overline{k}$ $\leftrightarrow$
$\alpha k^{\star}$ $+$ $6(\alpha  - 1)m$ $\le$ $\overline{k}$ $\leftrightarrow$
$\alpha k^{\star}$ $-$ $6(1 - \alpha)m$ $\le$ $\overline{k}$.

Now, we already have $\frac{7}{8}$-approximation algorithm.
Therefore, $k^{\star}$ $\ge$ $\frac{7}{8}m$ and $\frac{8}{7}k^{\star}$ $\ge$ $m$.

As a result, $\overline{k}$ $\ge$
$\alpha k^{\star}$ $-$ $6(1 - \alpha)m$ $\ge$
$\alpha k^{\star}$ $-$ $6(1 - \alpha)\frac{8}{7}k^{\star}$ $=$
$(\alpha - 6(1 - \alpha)\frac{8}{7})k^{\star}$ $=$
$(\frac{55}{7}\alpha - \frac{48}{7})k^{\star}$.

Notice that $m$ $\le$ $\frac{8}{7}k^{\star}$ $\leftrightarrow$
$-$ $\frac{8}{7}k^{\star}$ $\le$ $-$ $m$ $\leftrightarrow$
$-$ $6(1 - \alpha)\frac{8}{7}k^{\star}$ $\le$ $-$ $6(1 - \alpha)m$.

If there is $\alpha &gt; \frac{433}{440}$,
$\overline{k}$ $\ge$
$(\frac{55}{7}\alpha - \frac{48}{7})k^{\star}$ $&gt;$
$(\frac{55}{7}\frac{433}{440} - \frac{48}{7})k^{\star}$ $=$
$(\frac{7}{8})k^{\star}$.

Now, we show that such $\alpha$-approximation for MAX 2SAT can be used to give $(\frac{7}{8} + \epsilon)$-approximation algorithm for MAX-E3SAT problem for some constant $\epsilon &gt; 0$ and $\alpha &gt; \frac{433}{440}$.
Which is a contradiction.
Therefore, there is no such an approximation algorithm.</content><author><name>Programelot</name></author><category term="algorithm" /><category term="approximation" /><summary type="html">MAX-E3SAT is a problem that finds a truth value assignment that satisfies the maximum number of clauses for a given a set of clause which contains exactly three literals.</summary></entry><entry><title type="html">Approximation algorithm(13) - Buy-at-bulk network design</title><link href="https://programelot.github.io/2021/05/26/Approximation-algorithm(13)/" rel="alternate" type="text/html" title="Approximation algorithm(13) - Buy-at-bulk network design" /><published>2021-05-26T00:00:00+09:00</published><updated>2021-05-26T00:00:00+09:00</updated><id>https://programelot.github.io/2021/05/26/Approximation%20algorithm(13)</id><content type="html" xml:base="https://programelot.github.io/2021/05/26/Approximation-algorithm(13)/">In the real world, it is usually cheaper when you buy some thing in a bulk because of the delivery costs.
Now think about a undirected graph $G$ $=$ $(V,E)$ with length $l_e$ $\ge$ $0$ for all $e$ $\in$ $E$.
This problem requires $k$ pairs of vertices $(s_i,t_i)$ and demand $d_i$.
One thing that makes this problem interesting is that there is a cost function $f(u)$ such that satisfies following.

1. $f(0)$ $=$ $0$
2. $f$ is non-decreasing.
3. $f$ is subadditive which means $f(x + y)$ $\le$ $f(x)$ $+$ $f(y)$ for all $x, y$ $\in$ $\mathbb{N}$

Now problem asks to find $k$ paths from $s_i$ to $t_i$ with capacity $c:E \rightarrow \mathbb{N}$
to minimize $\sum\limits_{e \in E}f(c_e)l_e$
such that for any edge we can send $d_i$ units of commodity from $s_i$ to $t_i$ at the same time without violating $c$.

Notice that this algorithm can be solved in polynomial time if $G$ is a tree.
The reason is like follow.
If you think about any possible path on a tree, there is a unique path from $u$ to $v$ where $u,v$ $\in$ $V$.
Therefore, solution is just find a unique path and set the capacity and that's all.
Notice that this means it's not just in polynomial time but it gives a trivial unique solution.

Now, let's consider the following algorithm.

&lt;div class=&quot;algTab&quot;&gt;
    $\operatorname{for}$ each pair of vertices $u,v$ in $V$&lt;div class=&quot;algTab&quot;&gt;
        $P_{uv}$ be the shortest path from $u$ to $v$ in $E$
    &lt;/div&gt;
    $d_{uv}$ be the length of shortest path from $u$ to $v$.&lt;br&gt;
    Find a tree metric $(V',T)$ that approximates $d$&lt;br&gt;
    $\operatorname{for}$ each pair of vertices $u,v$ in $V$&lt;div class=&quot;algTab&quot;&gt;
        $P'_{uv}$ be the shortest path from $u$ to $v$ in $T$
    &lt;/div&gt;
    $c_e \leftarrow 0$ for all $e$ $\in$ $E$&lt;br&gt;
    $\operatorname{for}$ each pair $s_i, t_i$&lt;div class=&quot;algTab&quot;&gt;
        $\operatorname{for}$ each edge $(u,v)$ in $P'_{s_i t_i}$&lt;div class=&quot;algTab&quot;&gt;
            $\operatorname{for}$ each edge $e$ in $P_{u v}$&lt;div class=&quot;algTab&quot;&gt;
                Increase $c_e$ $\leftarrow$ $c_e$ $+$ $d_i$ 
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    return $c$
&lt;/div&gt;

First of all, we need to show that there is a tree metric.
Therefore we need to show that $d$ is a pseudometric.
Notice that most of properties are trivial but only triangular inequality need to be more detial.
Now, let's think about any path between $(x,y)$ and $(y,z)$.
Then, $d_{xy}$ $+$ $d_{yz}$ $=$
$\sum\limits_{e \in P_{xy}}l_e$ $+$ $\sum\limits_{e \in P_{yz}}l_e$ $=$
$\sum\limits_{e \in P_{xy} \cup P_{yz}}l_e$ $\ge$ 
$\sum\limits_{e \in P_{xz}}l_e$ $=$ 
$d_{xz}$.
Notice that concatinating path from $x$ to $y$ and path from $y$ to $z$ is a path from $x$ to $z$.
Which means at least longer or equal than &quot;shortest&quot; path from $x$ to $z$ in other world $P_{xy} \cup P_{yz}$ $\supseteq$ $P_{xz}$.

Now, problem is that we need to go through some $x$ that was not in $V$ but is in $V'$.
Therefore, we need to remove every such vertices.

Here is another algorithm that gives a tree metric from a tree metric.
&lt;div class=&quot;algTab&quot;&gt;
    $\operatorname{fit}$(V, V', T)&lt;div class=&quot;algTab&quot;&gt;
        $T' \leftarrow T$&lt;br&gt;
        $\operatorname{while}$ $\exists v \in V$ and $v$'s parent $w$ such that $w$ was not a left node of $T$&lt;div class=&quot;algTab&quot;&gt;
            Merge $v$ and $w$ to $v$
        &lt;/div&gt;
        Multiply the length of every edge of $T'$ by 4&lt;br&gt;
        return $(V, T')$
    &lt;/div&gt;
&lt;/div&gt;

If given a tree metric $T$ can be like follow.&lt;br&gt;
&lt;canvas id=&quot;canvas1&quot; width=&quot;200&quot; height=&quot;200&quot; style=&quot;border:1px solid #d3d3d3;&quot;&gt;
    Your browser does not support the HTML canvas tag.&lt;/canvas&gt;&lt;br&gt;
Then, other tree metric $T'$ can be like follow.&lt;br&gt;
&lt;canvas id=&quot;canvas2&quot; width=&quot;200&quot; height=&quot;200&quot; style=&quot;border:1px solid #d3d3d3;&quot;&gt;
    Your browser does not support the HTML canvas tag.&lt;/canvas&gt;&lt;br&gt;
&lt;script language = &quot;javascript&quot;&gt;
    c = document.getElementById(&quot;canvas1&quot;);
    ctx = c.getContext(&quot;2d&quot;);
    ctx.fillStyle = &quot;white&quot;;
    ctx.fillRect(0, 0, c.width, c.height);
  	ctx.beginPath();
    ctx.fillStyle = &quot;black&quot;;
  	ctx.moveTo(175, 170);
  	ctx.lineTo(125, 110);
  	ctx.lineTo(100, 40);
  	ctx.lineTo(75, 110);
  	ctx.lineTo(25, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(75, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(125, 170);
    ctx.stroke();
    ctx.fillStyle = &quot;white&quot;;
    ctx.beginPath();
    ctx.arc(25, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(175, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(100, 40, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.textAlign = &quot;center&quot;;
    ctx.fillStyle = &quot;red&quot;;
    ctx.font = &quot;15px Arial&quot;;
    ctx.fillText('4', 80, 80);
    ctx.fillText('4', 120, 80);
    ctx.fillText('2', 160, 140);
    ctx.fillText('2', 110, 140);
    ctx.fillText('2', 65, 145);
    ctx.fillText('2', 45, 140);
    ctx.fillText('{A,B,C,D}', 100, 40);
    ctx.fillText('{A,B,C}', 75, 110);
    ctx.fillText('{D}', 125, 110);
    ctx.fillText('{A}', 25, 170);
    ctx.fillText('{B}', 75, 170);
    ctx.fillText('{C}', 125, 170);
    ctx.fillText('{D}', 175, 170);
    c = document.getElementById(&quot;canvas2&quot;);
    ctx = c.getContext(&quot;2d&quot;);
    ctx.fillStyle = &quot;white&quot;;
    ctx.fillRect(0, 0, c.width, c.height);
  	ctx.beginPath();
    ctx.fillStyle = &quot;black&quot;;
  	ctx.moveTo(100, 40);
  	ctx.lineTo(75, 110);
  	ctx.lineTo(25, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(125, 170);
    ctx.stroke();
    ctx.fillStyle = &quot;white&quot;;
    ctx.beginPath();
    ctx.arc(25, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(100, 40, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.textAlign = &quot;center&quot;;
    ctx.fillStyle = &quot;red&quot;;
    ctx.font = &quot;15px Arial&quot;;
    ctx.fillText('16', 70, 80);
    ctx.fillText('8', 110, 140);
    ctx.fillText('8', 45, 140);
    ctx.fillText('{A}', 25, 170);
    ctx.fillText('{B}', 75, 110);
    ctx.fillText('{C}', 125, 170);
    ctx.fillText('{D}', 100, 40);
&lt;/script&gt;

Then, this algorithm returns a tree metric on $V$ such that $T_{uv}$ $\le$ 
$T'\_{uv}$ $\le$ 
$4T\_{uv}$ for all $u,v$ $\in$ $V$.
Notice that $T$ above is a result of original tree metric approximation algorithm.
Proof is like follow.

First, $T'\_{uv}$ $\le$ $T\_{uv}$ untill we multiply 4 because we only merge the vertices.
Therefore, $T'\_{uv}$ $\le$ $4T\_{uv}$ is true at the end of the algorithm.

Now, let's recap some facts from the tree metric $T$.

1. $\mathcal{L}_n$ is the level of the $n$. Notice that level of root node is $\log_2 \Delta$ and level of leaf node is $0$.
2. $\mathcal{A}_{uv}$ is the least common ancestor of $u$ and $v$.

Then, $T_{uv}$ $=$ 
$2\sum_{k=1}^{\mathcal{L}\_{\mathcal{A}\_{uv}}}2^k$ $=$ 
$2^{\mathcal{L}_{\mathcal{A}\_{uv}} + 2} - 4$ is true.

Now, let's think about the smallest possible length for $T'\_{uv}$.
Then, $u$ and $v$ will go only to the parent and the possible most go is right below $\mathcal{A}\_{uv}$.
One of $u$ and $v$ may be can be merged to $\mathcal{A}\_{uv}$ but not other one of $u$ and $v$ can be $\mathcal{A}\_{uv}$.
As a result, one of edge from $\mathcal{A}\_{uv}$ to child will still left to exist.
Therefore, $T'\_{uv}$ $\ge$
$4 \cdot 2^{\mathcal{L}\_{\mathcal{A}\_{uv}}}$ $=$ 
$2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 2}$ $\ge$
$2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 2} - 4$ $=$
$T_{uv}$
Therefore, claim holds.

Notice that this means $d_{uv}$ $\le$ $T_{uv}$ $\le$ $T'\_{uv}$ and $E[T'\_{uv}]$ $\le$ $E[4T_{uv}]$ $=$ $4E[T_{uv}]$ $\le$ $O(\ln \left\vert V \right\vert)d_{uv}$.
Therefore, $d_{uv}$ $\le$ $T'\_{uv}$ and $E[T'\_{uv}]$ $\le$ $O(\ln \left\vert V \right\vert)d_{uv}$.

Now, think about the algorithm follow.

&lt;div class=&quot;algTab&quot;&gt;
    $\operatorname{for}$ each pair of vertices $u,v$ in $V$&lt;div class=&quot;algTab&quot;&gt;
        $P_{uv}$ be the shortest path from $u$ to $v$ in $E$
    &lt;/div&gt;
    $d_{uv}$ be the length of shortest path from $u$ to $v$.&lt;br&gt;
    Find a tree metric $(V',T)$ that approximates $d$&lt;br&gt;
    $(V,T')$ $\leftarrow$ $\operatorname{fit}(V, V', T)$&lt;br&gt;
    $\operatorname{for}$ each pair of vertices $u,v$ in $V$&lt;div class=&quot;algTab&quot;&gt;
        $P'_{uv}$ be the shortest path from $u$ to $v$ in $T'$
    &lt;/div&gt;
    $c_e \leftarrow 0$ for all $e$ $\in$ $E$&lt;br&gt;
    $\operatorname{for}$ each pair $s_i, t_i$&lt;div class=&quot;algTab&quot;&gt;
        $\operatorname{for}$ each edge $(u,v)$ in $P'_{s_i t_i}$&lt;div class=&quot;algTab&quot;&gt;
            $\operatorname{for}$ each edge $e$ in $P_{u v}$&lt;div class=&quot;algTab&quot;&gt;
                Increase $c_e$ $\leftarrow$ $c_e$ $+$ $d_i$ 
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    return $c$
&lt;/div&gt;

Then this algorithm is a $O(\log n)$-approximation algorithm.
Proof is like follow.

Let's denote some terminologies.
1. $P^{\star}\_{u v}$ is the shortest path between $u$ and $v$ from the optimal solution.
2. $c^{\star}_e$ for $e$ $\in$ $E$ is the capacity of $e$ from the optimal solution.
3. $\operatorname{OPT}$ is the optimal solution; $\operatorname{OPT}$ $=$ 
$\sum\limits_{e \in E}f(\sum\limits_{i = 1 : e \in P^{\star}\_{s_i t_i}}^{k} d_i)l_e$ $=$ 
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1 : (u,v) \in P^{\star}\_{s_i t_i}}^{k} d_i)d\_{uv}$ $=$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}_{s_i t_i})) d\_{uv}$.
4. $P'\_{u v}$ is the unique shortest path between $u$ and $b$ from the $T'$.
5. $P^{S}\_{u v}$ is a path that changes each edge $(x,y)$ in $P^{\star}\_{u v}$ to $P'\_{x, y}$.
6. $\operatorname{OPT'}$ is the solution from $P^{S}\_{s_i t_i}$; $\operatorname{OPT'}$ $=$
$\sum\limits_{e \in T'}f(\sum\limits_{i = 1 : e \in P^{S}\_{s_i t_i}}^{k} d_i)l\_e$ $=$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}$.

Notice that $P^{S}\_{s_i t_i}$ may not be simple.
Then, $E[\operatorname{OPT'}]$ $=$
$E[\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}]$ $\le$
$E[\sum\limits_{(x,y) \in T'} \sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}]$ $=$
$E[\sum\limits_{(u,v) \in E} \sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}]$ $=$
$E[\sum\limits_{(u,v) \in E} \sum\limits_{(x,y) \in P'\_{u v}} f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i}))T'\_{xy}]$ $=$
$\sum\limits_{(u,v) \in E} E[ \sum\limits_{(x,y) \in P'\_{u v}} f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i}))T'\_{xy}]$ $=$
$\sum\limits_{(u,v) \in E} E[ f(\sum\limits_{i = 1}^{k}d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) \sum\limits_{(x,y) \in P'\_{u v}}T'\_{xy}]$ $=$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) E[ \sum\limits_{(x,y) \in P'\_{u v}}T'\_{xy}]$ $=$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) E[T'\_{uv}]$ $\le$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) O(\ln \left\vert V \right\vert)d_{uv}$ $=$
$O(\ln \left\vert V \right\vert) \sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i})) d_{uv}$ $=$
$O(\ln \left\vert V \right\vert) \operatorname{OPT}$.

Notice that following facts.
First inequality holds because $f$ is subadditive.
Third equality holds because $P'\_{uv}$ $\in$ $T'$.
Sixth equality holds because $f(\sum\limits_{i = 1}^{k} d\_i \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i}))$ is independent from $u,v$.
Seventh equality holds because $\sum\limits_{(x,y) \in P'\_{u v}}T'\_{xy}$ is the distance from $u$ to $v$.
Therefore claim holds.

Simiallary, following is true.

Now let's denote $\operatorname{ALG}$ as the value of the output solution.
Then, $\operatorname{ALG}$ $=$
$\sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(x,y) \in T'} \mathbb{1}((x,y) \in P'\_{s_i t_i} \text{ and } (u,v) \in P\_{xy}))d\_{uv}$ $\le$
$\sum\limits_{(u,v) \in E} \sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i} \text{ and } (u,v) \in P\_{xy}))d\_{uv}$ $=$
$\sum\limits_{(x,y) \in T'} \sum\limits_{(u,v) \in E} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i} \text{ and } (u,v) \in P\_{xy}))d\_{uv}$ $=$
$\sum\limits_{(x,y) \in T'} \sum\limits_{(u,v) \in P_{xy}} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i}))d\_{uv}$ $=$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i})) \sum\limits_{(u,v) \in P_{xy}}d\_{uv}$ $=$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i})) d\_{xy}$ $\le$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i})) T'\_{xy}$ $\le$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}$ $=$
$\operatorname{OPT'}$.

All eqaulities and inequalities except last ineuqality can be proven in the same way with above.
Therefore, we need to show only last inequality holds.

Proof for &quot;$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \mathbb{1}((x,y) \in P'\_{s_i t_i})) T'\_{xy}$ $\le$
$\sum\limits_{(x,y) \in T'} f(\sum\limits_{i = 1}^{k} d_i \sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}))T'\_{xy}$&quot; is like follow.

Let's think about &quot;$\mathbb{1}((x,y) \in P'\_{s_i t_i})$&quot; and 
&quot;$\sum\limits_{(u,v) \in E} \mathbb{1}((u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v})$&quot; for some $x, y, i$.

Then first one is $1$ if $(x,y) \in P'\_{s_i t_i}$ and $0$ otherwise.
Therefore, there is nothing to show if $(x,y) \not\in P'\_{s_i t_i}$.
Now, let's assume that $(x,y) \in P'\_{s_i t_i}$.
Then, $P^{\star}\_{s_i t_i}$ should include at least $(s_i,t_i)$ or longer path from $s_i$ to $t_i$ for any $i$.
Which means the cardinarity of $\\{(u,v) \in P^{\star}\_{s_i t_i} \text{ and } (x,y) \in P'\_{u v}\\}$ should be bigger or equal than $1$.
Therefore, claim holds.
Notice that concatinating $(u,v) \in P^{\star}\_{s_i t_i}$ in $T'$ will be a valid path from $u$ to $v$.
Therefore, $(x,y)$ should be in some where in there.

As a result, $\operatorname{ALG}$ $\le$ $\operatorname{OPT'}$ $\le$ $O(\ln \left\vert V \right\vert) \operatorname{OPT}$.
Therefore claim holds.

Notice that algorithm runs in a polynomial time.</content><author><name>Programelot</name></author><category term="algorithm" /><category term="approximation" /><summary type="html">In the real world, it is usually cheaper when you buy some thing in a bulk because of the delivery costs. Now think about a undirected graph $G$ $=$ $(V,E)$ with length $l_e$ $\ge$ $0$ for all $e$ $\in$ $E$. This problem requires $k$ pairs of vertices $(s_i,t_i)$ and demand $d_i$. One thing that makes this problem interesting is that there is a cost function $f(u)$ such that satisfies following.</summary></entry><entry><title type="html">Useful mathematical tools</title><link href="https://programelot.github.io/2021/05/19/Useful-mathematical-tools/" rel="alternate" type="text/html" title="Useful mathematical tools" /><published>2021-05-19T00:00:00+09:00</published><updated>2021-05-19T00:00:00+09:00</updated><id>https://programelot.github.io/2021/05/19/Useful%20mathematical%20tools</id><content type="html" xml:base="https://programelot.github.io/2021/05/19/Useful-mathematical-tools/">1. $\ln n$ $\le$ $\sum\limits_{k = 1}^{n} \frac{1}{k}$ $\le$ $\ln n$ $+$ $1$ for $n$ $\in$ $\mathbb{Z}^{+}$
2. $\sum\limits_{k = 1}^{n}ar^{k-1}$ $=$ $a\frac{r^{n} - 1}{r - 1}$ if $r$ $\neq$ $1$, $n$ $\in$ $\mathbb{Z}$</content><author><name>Programelot</name></author><category term="algorithm" /><category term="approximation" /><summary type="html">$\ln n$ $\le$ $\sum\limits_{k = 1}^{n} \frac{1}{k}$ $\le$ $\ln n$ $+$ $1$ for $n$ $\in$ $\mathbb{Z}^{+}$ $\sum\limits_{k = 1}^{n}ar^{k-1}$ $=$ $a\frac{r^{n} - 1}{r - 1}$ if $r$ $\neq$ $1$, $n$ $\in$ $\mathbb{Z}$</summary></entry><entry><title type="html">Approximation of metrics by tree metrics</title><link href="https://programelot.github.io/2021/05/19/tree-metrics/" rel="alternate" type="text/html" title="Approximation of metrics by tree metrics" /><published>2021-05-19T00:00:00+09:00</published><updated>2021-05-19T00:00:00+09:00</updated><id>https://programelot.github.io/2021/05/19/tree%20metrics</id><content type="html" xml:base="https://programelot.github.io/2021/05/19/tree-metrics/">For a given vertices $V$ and distance $V \times V \rightarrow \mathcal{R} : d$.
$(V,d)$ is so called a metric if following properties are hold.

1. $d_{uv}$ $\ge$ $0$ for all $u,v$ $\in$ $V$
2. $d_{uv}$ $=$ $0$ iff $u = v$
3. $d_{uv}$ $=$ $d_{vu}$ for all $u,v$ $\in$ $V$
4. (Triangular inequality) $d_{uv}$ $\le$ $d_{uw}$ $+$ $d_{wv}$ for all $u,v,w$ $\in$ $V$

Notice that we say it is a pseudometric if property 2 changes to &quot;$d_{uv}$ $=$ $0$ if $u = v$&quot;.

A tree metic $(V', T)$ for a set of vertices $V$ is a tree $T$ defined on a set of nodes $V' \supseteq V$, whoese edges are given non negative lengths.
For $u,v$ $\in$ $V'$, let $T_{uv}$ denote the length of the unique path between $u$ and $v$ in $T$.

Notice that tree matrix is a matric.
It is trivial to be hold for 1 ~ 3.
For 4, if there is a path $u$ to $w$ and $w$ to $v$, then concatinating them is a path from $u$ to $v$.
It will have the length equal or less than sum of each path because there could be a cycle and it can be removed.

Given a metric $d$ on $V$, we say a tree metric $(V', T)$ is a $\operatorname{tree metic embedding}$ of distortion $\alpha$ if $d_{uv}$ $\le$ $T_{uv}$ $\le$ $\alpha d_{uv}$ for all $u,v$ $\in$ $V$.

However, do we even have any approximation for it in every time?
Yes, if we have gigantic distortion.
However, it's no with some distortion.
In fact it is known that there is no tree metric has distortion less than $\frac{n - 1}{8}$ for some metric $d$ on $n$ vertices.
However there is a good theorem.

Given a metric $d$ on $V$ such that $d_{uv}$ $\ge$ $1$ for all $u$ $\neq$ $v$, there exists a randomized algorithm that finds a tree metric $(V', T)$ such that for all $u, v$ $\in$ $V$, $d_{uv}$ $\le$ $T_{uv}$ and $E[T_{uv}]$ $\le$ $O(\ln \left\vert V \right\vert)d_{uv}$.
Notice that this randomized algorithm picks a tree metric from a given graph.
Proof is like follow.

Consider the following algorithm where $B(x, r)$ is a hypersphere with the center at $x$ and radius of $r$.
&lt;div class=&quot;algTab&quot;&gt;
    Pick $r_0$ $\in$ $[\frac{1}{2}, 1)$ uniformly at random&lt;br&gt;
    Choose $\Delta$ as the smallest power of two greater or equal than $2\max_{u,v \in V}d_{uv}$&lt;br&gt;
    Let $r_i$ $=$ $2^ir_0$ for $1$ $\le$ $i$ $\le$ $\log_2 \Delta$&lt;br&gt;
    Pick a permutation $\pi$ of $v$ uniformly at random&lt;br&gt;
    $\mathcal{C}(\log_2 \Delta) \leftarrow \{V\}$&lt;br&gt;
    Create a node corresponding to $V$ and make it the root node&lt;br&gt;
    $\operatorname{for}$ $i \leftarrow \log_2 \Delta, \log_2 \Delta - 1, \cdots, 1$&lt;div class=&quot;algTab&quot;&gt;
        $\mathcal{C}(i - 1) \leftarrow \emptyset$&lt;br&gt;
        $\operatorname{for}$ $C \in \mathcal{C}(i)$&lt;div class=&quot;algTab&quot;&gt;
            $S \leftarrow C$&lt;br&gt;
            $\operatorname{for}$ $j \leftarrow 1, 2, \cdots, \left\vert V \right\vert$&lt;div class=&quot;algTab&quot;&gt;
                $\operatorname{if}$ $B(\pi(j), r_{i-1})$ $\cap$ $S$ $\neq$ $\emptyset$&lt;div class=&quot;algTab&quot;&gt;
                    Add $\{B(\pi(j), r_{i-1}) \cap S\}$ to $\mathcal{C}(i -1)$&lt;br&gt;
                    $S$ $\leftarrow$ $S$ $-$ $(B(\pi(j), r_{i-1}) \cap S)$
                &lt;/div&gt;
            &lt;/div&gt;
            Create nodes corresponding to each set in $\mathcal{C}(i -1)$ and attach each node to the node in $\mathcal{C}(i)$ corresponding to its superset by an edge of length $2^i$
        &lt;/div&gt;
    &lt;/div&gt;
    $V' \leftarrow$ all nodes in $\bigcup\limits_{k = 0}^{\log_2 \Delta}\mathcal{C}(k)$&lt;br&gt;
    $T \leftarrow$ all edges between $\mathcal{C}(k)$ and $\mathcal{C}(k - 1)$ for all $1$ $\le$ $k$ $\le$ $\log_2 \Delta$&lt;br&gt;
    return $(V', T)$ 
&lt;/div&gt;

For an example, following graph's result will be like follow.

If given metric is like follow.&lt;br&gt;
&lt;canvas id=&quot;canvas1&quot; width=&quot;200&quot; height=&quot;200&quot; style=&quot;border:1px solid #d3d3d3;&quot;&gt;
    Your browser does not support the HTML canvas tag.&lt;/canvas&gt;&lt;br&gt;
Returned tree metric can be like follow.&lt;br&gt;
&lt;canvas id=&quot;canvas2&quot; width=&quot;200&quot; height=&quot;200&quot; style=&quot;border:1px solid #d3d3d3;&quot;&gt;
    Your browser does not support the HTML canvas tag.&lt;/canvas&gt;&lt;br&gt;
&lt;script language = &quot;javascript&quot;&gt;
    let c = document.getElementById(&quot;canvas1&quot;);
    let ctx = c.getContext(&quot;2d&quot;);
    ctx.fillStyle = &quot;white&quot;;
    ctx.fillRect(0, 0, c.width, c.height);
    ctx.fillStyle = &quot;white&quot;;
    ctx.beginPath();
    ctx.arc(100, 100, 80, 0, 2*Math.PI);
    ctx.stroke();
    ctx.beginPath();
    ctx.arc(100, 180, 10, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(100, 20, 10, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(20, 100, 10, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(180, 100, 10, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.textAlign = &quot;center&quot;;
    ctx.fillStyle = &quot;red&quot;;
    ctx.font = &quot;20px Arial&quot;;
    ctx.fillText('A', 100, 180);
    ctx.fillText('B', 100, 20);
    ctx.fillText('C', 20, 100);
    ctx.fillText('D', 180, 100);
    ctx.fillText('1', 44, 44);
    ctx.fillText('1', 156, 44);
    ctx.fillText('1', 44, 156);
    ctx.fillText('1', 156, 156);
    c = document.getElementById(&quot;canvas2&quot;);
    ctx = c.getContext(&quot;2d&quot;);
    ctx.fillStyle = &quot;white&quot;;
    ctx.fillRect(0, 0, c.width, c.height);
  	ctx.beginPath();
    ctx.fillStyle = &quot;black&quot;;
  	ctx.moveTo(175, 170);
  	ctx.lineTo(125, 110);
  	ctx.lineTo(100, 40);
  	ctx.lineTo(75, 110);
  	ctx.lineTo(25, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(75, 170);
  	ctx.moveTo(75, 110);
  	ctx.lineTo(125, 170);
    ctx.stroke();
    ctx.fillStyle = &quot;white&quot;;
    ctx.beginPath();
    ctx.arc(25, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(175, 170, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(75, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(125, 110, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.beginPath();
    ctx.arc(100, 40, 20, 0, 2*Math.PI);
    ctx.stroke();
    ctx.fill();
    ctx.textAlign = &quot;center&quot;;
    ctx.fillStyle = &quot;red&quot;;
    ctx.font = &quot;15px Arial&quot;;
    ctx.fillText('4', 80, 80);
    ctx.fillText('4', 120, 80);
    ctx.fillText('2', 160, 140);
    ctx.fillText('2', 110, 140);
    ctx.fillText('2', 65, 145);
    ctx.fillText('2', 45, 140);
    ctx.fillText('{A,B,C,D}', 100, 40);
    ctx.fillText('{A,B,C}', 75, 110);
    ctx.fillText('{D}', 125, 110);
    ctx.fillText('{A}', 25, 170);
    ctx.fillText('{B}', 75, 170);
    ctx.fillText('{C}', 125, 170);
    ctx.fillText('{D}', 175, 170);
&lt;/script&gt;

Now, following is true if we call the deepest nodes as level 0 and level $i$'s parent as level $i + 1$.
Note that each node at level 0 corresponding to a singleton and every vertex in $V$ appears exactly once.
The reason is that there can't be more than center itself because $r_0$ $&lt;$ $1$ $\le$ $d_{uv}$ for all $u,v$ $\in$ $V$.
Notice that every vertex at level $i$ is belongs to a hyper sphere of radius $r_i$ and centered by one of vertex in side of the set.
Which also means that level $\log_2 \Delta$ will contain entire $V$ because $r_{\log_2 \Delta}$ $=$ $2^{\log_2 \Delta} r_0$ $\ge$ $2^{\log_2 \Delta} \frac{1}{2}$ $=$ $\Delta \frac{1}{2}$ $\ge$ $2\max_{u,v \in V}d_{uv}\frac{1}{2}$ $=$ $\max_{u,v \in V}d_{uv}$.

Now, let's denote some terminologies for a node $n$ in the $(V', T)$.
1. $\mathcal{L}_n$ is the level of the $n$. Notice that level of root node is $\log_2 \Delta$ and level of leaf node is $0$.
2. $\mathcal{S}_n$ is the set of vertices which the corresponding hyper sphere includes.

Then, there are some facts.
1. $d_{yz}$ $\le$ $2r_{\mathcal{L}_n}$ for any $y,z$ $\in$ $\mathcal{S}_n$ becuase it should be in the same hyper sphere.
2. For any $u,v$ $\in$ $V$, they can't belongs to the same node at level $[\log_2 d_{uv}] - 1$ because otherwise $d_{uv}$ $\le$ $2r_{[\log_2 d_{uv}] - 1}$ $=$ $2 \cdot 2^{[\log_2 d_{uv}] - 1}r_0$ $=$ $2^{[\log_2 d_{uv}]}r_0$ $\le$ $2^{\log_2 d_{uv}}r_0$ $=$ $d_{uv}r_0$ $&lt;$ $d_{uv}$ which is a contradiction.

Then, $T_{uv}$ $\ge$ $d_{uv}$ is true.
Proof is like follow.
If $d_{uv}$ $&lt;$ $4$ then, $T_{uv}$ $\ge$ $d_{uv}$ because $T_{uv}$ $\ge$ $4$.
Notice that $T_{uv}$ $\ge$ $4$ is true because all edges in the $T$ is bigger or equal than $2$ and there should be at least one parent to go $v$ from $u$.
Now, other cases are $d_{uv}$ $\ge$ $4$.
Frist, $d_{uv}$ $\le$ $\sum\limits_{k = 0}^{[\log_2 d_{uv}]} 2^k$ because RHS is bigger than a binary representation of $d_{uv}$.
Then, $d_{uv}$ $\le$ $\sum\limits_{k = 0}^{[\log_2 d_{uv}]} 2^k$ $=$ $\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ $+$ $1$ $\le$ $\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ $+$ $\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ $=$ $2\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ $\le$ $T_{uv}$.
Notice that last inequality comes from the fact 2 above.
If we think about path from $u$ to $v$, it should go to at least level $[\log_2 d_{uv}]$ because it can't belongs to the same node untill level $[\log_2 d_{uv}] - 1$.
Also, $2\sum\limits_{k = 1}^{[\log_2 d_{uv}]} 2^k$ is a sum of length from $u$ to $v$ via level $[\log_2 d_{uv}]$.
Therefore, claim holds.

Now there are only one thing to show that $E[T_{uv}]$ $\le$ $O(\ln \left\vert V \right\vert)d_{uv}$.

To show this, there some terminologies to define.

1. $\mathcal{A}_{uv}$ is the least common ancestor of $u$ and $v$.
2. We say $w$ settles the pair of $u$ and $v$ on $i$ if $w$ is the first vertex in permutation $\pi$ such that at least one of $u$ and $v$ is in the hypersphere $B(w, r_i)$.
3. We say $w$ cut $u$ and $v$ on level $i$ if exactly one of $u$ and $v$ is in the hypersphere $B(w, r_i)$.
4. $X_{iw}(u,v)$ be the event that $w$ cuts $(u, v)$ on level $i$.
5. $S_{iW}(u,v)$ be the event that $w$ settles $(u, v)$ on level $i$.
6. $\mathbb{1}(x)$ is an indicator fuction such that $1$ if $x$ is true $0$ otherwise.

First, $T_{uv}$ $=$ 
$2\sum_{k=1}^{\mathcal{L}\_{\mathcal{A}\_{uv}}}2^k$ $=$ 
$2(2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 1} - 2)$ $=$ 
$2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 2} - 4$ $\le$ 
$2^{\mathcal{L}\_{\mathcal{A}\_{uv}} + 2}$.

Then, $T_{uv}$ $\le$ $\max\limits_{i = 0}^{\log_2 \Delta - 1} \mathbb{1}(\exists X_{iw}(u,v) \cap S_{iw}(u,v) \text{ for } w \in V) 2^{i + 3}$.

Notice that $\operatorname{argmax}\limits_{i = 0}^{\log_2 \Delta - 1} \mathbb{1}(\exists X_{iw}(u,v) \cap S_{iw}(u,v) \text{ for } w \in V)2^{i + 3}$ is the $\mathcal{A}_{uv}$.

Therefore, $T_{uv}$ $\le$ $\max\limits_{i = 0}^{\log_2 \Delta - 1} \mathbb{1}(\exists X_{iw}(u,v) \cap S_{iw}(u,v) \text{ for } w \in V) 2^{i + 3}$
$\le$ $\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} \mathbb{1}(\exists X_{iw}(u,v) \cap S_{iw}(u,v)) 2^{i + 3}$.

Now if we go back to the algorithm, there are two random events at the algorithm which are &quot;picking $r_0$&quot; and &quot;picking a random permutation $\pi$&quot;.
Therefore, we can average on certain path to select $T_{uv}$.
Then, $E[T_{uv}]$ $\le$ $\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v) \cap S_{iw}(u,v)] 2^{i + 3}$.
Notice that existance of $X_{iw}(u,v) \cap S_{iw}(u,v)$ for $w$ $\in$ $V$ on level $i$ will be depend on random varaibles and other things are indepedent with the random variable.

Now, let's consider followings.

With out loosing generality, let's assume that $d_{uw}$ $\le$ $d_{vw}$ for $w$ that cuts $u$ and $v$ on level $i$.
Then, $d_{uw}$ $\le$ $r_i$ $&lt;$ $d_{vw}$ because $u$ should be in $B(w, r_i)$ and $v$ shouldn't.
With above, we need to select $r_i$ uniformly at random with $2^ir_0$.
Then we will pick $r_i$ in $[2^{i-1},2^i)$ because we will pick $r_0$ in $[\frac{1}{2}, 1)$. 
Now, let's think about the $Pr[X_{iw}(u,v)]$.
Then, $Pr[X_{iw}(u,v)]$ $=$ $\frac{\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert}{\left\vert [2^{i-1}, 2^i \right\vert}$ $=$ $\frac{\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert}{2^{i-1}}$.
As a result, $\sum\limits_{i=0}^{\log_2 \Delta - 1}Pr[X_{iw}(u,v)]2^{i + 3}$ $=$ 
$\sum\limits_{i=0}^{\log_2 \Delta - 1}\frac{\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert}{2^{i-1}}2^{i + 3}$ $=$
$\sum\limits_{i=0}^{\log_2 \Delta - 1}\frac{2^{i + 3}}{2^{i-1}}\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert$ $=$
$2^4\sum\limits_{i=0}^{\log_2 \Delta - 1}\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert$ $=$
$16\sum\limits_{i=0}^{\log_2 \Delta - 1}\left\vert [2^{i-1}, 2^i) \cap [d_{uw}, d_{vw}) \right\vert$ $=$
$16\left\vert [d_{uw}, d_{vw}) \right\vert$ for any $w$.
Notice that $\bigcup\limits_{i=0}^{\log_2 \Delta - 1}[2^{i-1}, 2^i)$ $=$ $[2^{-1}, 2^{\log_2 \Delta - 1})$ $=$ $[2^{-1}, 2^{-1}\Delta)$ $=$ $[2^{-1}, 2^{-1}2\max_{u,v \in V}d_{uv})$ $=$ $[2^{-1}, \max_{u,v \in V}d_{uv})$ $\supseteq$ set of possible $d_{uv}$ for all $u,v$ $\in$ $V$.
Which means it will see all possible area.
Notice that $d_{uv}$ $\ge$ $1$ and $Pr[X_{iw}(u,v)]$ means probability that $w$ on level $i$ will cut $u$ and $v$.
As a result, $Pr[X_{iw}(u,v)]$ $=$ $16\left\vert [d_{uw}, d_{vw}) \right\vert$ $=$ $16(d_{vw} - d{uw})$ $\le$ $16(d_{vu} + d_{uw} - d_{uw})$ $=$ $16d_{vu}$ $=$ $16d_{uv}$ from the triangular inequality.

Now, let's think about list $\mathbb{L}$ from $V$ such that sorted in the order $\min(d_{ux}, d_{vx})$ for $x$ $\in$ $\mathbb{L}$.
Now, think about 2 things.

1. Some $w$ $\in$ $V$ such that $w$ cuts $u$ and $v$.
2. Let's denote $w$'s level as $i$.
3. Let's denote $w$'s index in $\mathbb{L}$ is $\mathcal{I}_w$

Then, one of $u$ or $v$ should be in $B(z, r_i)$ for any $z$ that has less index than $\mathcal{I}\_w$.
Notice that $\min(d_{uz}, d_{vz})$ $\le$ $\min(d_{uw}, d_{vw})$ $\le$ $r_i$ because it is sorted by $\min(d_{ux}, d_{vx})$ and $w$ cuts $u$ and $v$.
Then, $Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $\le$ $\frac{1}{\mathcal{I}\_w}$ because $w$ need to be placed in $\pi$ more previous than all such $z$s.
Notice that there are at least $\mathcal{I}\_w$ candiadates that can cut $u$ and $v$ and $w$ need to be the first on $\pi$ to settle $u$ and $v$.
Moreover, $\sum\limits_{w \in V}Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $\le$ $\sum\limits_{w \in V}\frac{1}{\mathcal{I}\_w}$ for a fixed $i$.
Notice that if we fix $i$, $\mathcal{I}\_w$ will be some arbitrary order of vertices.
However that will be still fixed in some way after set-up random variables.
Which means $\sum\limits_{w \in V}Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $=$ $\sum\limits_{w \in V : \mathcal{I}\_w = k, w \text{ cuts } u \text{ and } v}\frac{1}{k}$ $=$ $\sum\limits_{k = 1 : \mathcal{I}\_w = k, w \text{ cuts } u \text{ and } v}^{\left\vert V \right\vert}\frac{1}{k}$ $\le$ $\sum\limits\_{k = 1}^{\left\vert V \right\vert}\frac{1}{k}$ $\le$ $\ln \left\vert V \right\vert$ $+$ $1$.
Finally, notice that $\mathcal{I}_w$ doesn't depend on $i$ because it only depend on $\min(d\_{ux}, d\_{vx})$.
Infact, it doesn't even depend on any random varaible.

Now, following 4 things are true for summary.
1. $E[T_{uv}]$ $\le$ $\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v) \cap S_{iw}(u,v)] 2^{i + 3}$
2. $\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v)]2^{i + 3}$ $\le$ $16d_{uv}$
3. $Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $\le$ $\frac{1}{\mathcal{I}\_w}$
4. $\sum\limits_{w \in V} \frac{1}{\mathcal{I}\_w}$ $\le$ $\ln \left\vert V \right\vert$ $+$ $1$

As a result, $E[T_{uv}]$ $\le$
$\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v) \cap S_{iw}(u,v)] 2^{i + 3}$ $=$
$\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]Pr[X_{iw}(u,v)] 2^{i + 3}$ $=$
$\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v)]2^{i + 3} Pr[S_{iw}(u,v) \vert X_{iw}(u,v)]$ $\le$
$\sum\limits_{w \in V}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v)]2^{i + 3}\frac{1}{\mathcal{I}\_w}$ $=$
$\sum\limits_{w \in V}\frac{1}{\mathcal{I}\_w}\sum\limits_{i = 0}^{\log_2 \Delta - 1} Pr[X_{iw}(u,v)]2^{i + 3}$ $\le$
$\sum\limits_{w \in V}\frac{1}{\mathcal{I}\_w}16d_{uv}$ $=$
$16d_{uv}\sum\limits_{w \in V} \frac{1}{\mathcal{I}\_w}$ $\le$
$16d{uv}(\ln \left\vert V \right\vert + 1)$ $=$ $O(\ln \left\vert V \right\vert)d_{uv}$.

Therefore, claim holds.</content><author><name>Programelot</name></author><category term="algorithm" /><category term="approximation" /><summary type="html">For a given vertices $V$ and distance $V \times V \rightarrow \mathcal{R} : d$. $(V,d)$ is so called a metric if following properties are hold.</summary></entry><entry><title type="html">Graph coloring</title><link href="https://programelot.github.io/2021/05/15/Graph-coloring/" rel="alternate" type="text/html" title="Graph coloring" /><published>2021-05-15T00:00:00+09:00</published><updated>2021-05-15T00:00:00+09:00</updated><id>https://programelot.github.io/2021/05/15/Graph%20coloring</id><content type="html" xml:base="https://programelot.github.io/2021/05/15/Graph-coloring/">We need some definitions and theorems to discuss about the coloring.

## Definitions ##
1. A coloring of graph $G$ is an assignment of colors to the vertices of $G$.
In this case, it can be considered as the assignemnts of sets like vertex 1 to set 1 and vetex 2 to set 3 and so-on.
2. A graph is is $k$-coloring if each vertex is assigned to exactly one of $k$ colors.
3. A coloring is proper if no two adjacent vertices are assigned to the same color.
4. A graph is so-called $k$-colorable if it has a proper $k$-coloring.
5. We say $g(n)$ $=$ $\tilde{O}(f(n))$ if there exists some constant $c$ $\ge$ $0$ such that $g(n)$ $=$ $O(f(n))\ln^c$.
This is some extention that ignoring logarithmic terms.
6. We say coloring is a semicoloring if at most $\frac{\left\vert V \right\vert}{4}$ edges have endpoints with the same color.
Notice that semicoloring don't need to be proper.
It allows $\frac{\left\vert V \right\vert}{4}$ edges to be collide.

## Theorems ##
1. There is a polynomial time algorithm to check 2-colorable.
Notice that we can do it by DFS and checking there is some pair of vertices that colors collide.
2. It is known to be NP-hard to decide if a graph is 3-colorable.
3. It is known to be NP-hard to decide if a graph is 3-colorable or any of its proper coloring requires at least five colors.
This means input will give like 3-colorable, 5-colorable, 6-colorable, etc..
There will no 4-colorable inputs.
4. It is known to be NP-hard to find a 3-coloring from a 3-colorable graph.
Notice that if there is such an algorithm in polynomial time then running that algorithm and checking the result are enough to solve 3-colorable problem.
5. A graph with maximum degree $\delta$ can be $(\delta + 1)$-colored in polynomial time.
Notice that all of vertices never run out of colors in this case because even all the neighbors use seperate colors, there are still one color to use.
6. 3-colorable graph can be $O(\sqrt{n})$-colored in polynomial time for $n$ as the number of vertices.
7. There exists a polynomial time random algorithm that finds a semicoloring with $4\Delta^{\log_3 2}$ colors at least $\frac{1}{2}$ probability where $\Delta$ is the maximum degree of a graph with.
8. There is a polynomial algorithm that finds $\tilde{O}(n^{\log_6 2})$-coloring of a given 3-colorable graph at least $\frac{1}{2}$ probability.

## Proof of theorems ##

Theorem 6 can be done by following algorithm.
&lt;div class=&quot;algTab&quot;&gt;
    $\operatorname{while} \exists$ a vertex $v$ with at least degree $\sqrt{n}$&lt;div class=&quot;algTab&quot;&gt;
        Choose three new colors $c_1, c_2, c_3$&lt;br&gt;
        Color $v$ with $c_1$&lt;br&gt;
        Color neighbors of $v$ with $c_2, c_3$&lt;br&gt;
        Remove colored vertices
    &lt;/div&gt;
    Color the rest of graph with $\sqrt{n}$ new colors
&lt;/div&gt;
Notice that the neighbors of $v$ can be colored with 2 colors in each iteration because given graph is a 3-colorable graph.
The reason is that all of neighbor of $v$ can't be $c_1$ if we select $v$ as $c_1$.
Then, it's a 2-coloring problem which can be solve in polynomial time.
With that, $v$ and its neighbors are using distinct from other vertices because it producess new colors.
Notice that we can remove it because it uses independent color sets.
Now, it uses just $\sqrt{n}$ color at the last.
Therefore it's enough to show there are at most $O(\sqrt{n})$ iteration for &quot; $\operatorname{while} \exists$ a vertex $v$ with at least degree $\sqrt{n}$&quot;.
With that, it removes at least $\sqrt{n}I$ vetices from graph if we denote $I$ as the number of such an iteration because each vertices has $\sqrt{n}$ degree.
However, we can't remove more vetices than number of vertices at the beginning.
Therefore, $\sqrt{n}I$ $\le$ $n$.
As a result, $I$ $\le$ $\sqrt{n}$.
Notice that algorithm uses at most $4\sqrt{n}$ colors and it runs in a polynomial time.

&lt;br&gt;

Theorem 7 can be done by following algorithm.

Consider the following vector program for given graph $G$ $=$ $(V,E)$.
Let $n$ $=$ $\left\vert V \right\vert$
Minimize $\lambda$&lt;br&gt;
such that
    $v_i \cdot v_j \le \lambda$ for all $(i, j) \in E$&lt;br&gt;
    $v_i \cdot v_i = 1$ for all $i \in V$&lt;br&gt;
    $v_i \in \mathcal{R}^n$ for all $i \in V$&lt;br&gt;

Then, there is a feasible solution such that $v_i \cdot v_j$ $=$ $-\frac{1}{2}$ for all $(i,j) \in E$ if given graph is a 3-colorable graph.
Proof is like follow.

Consider an equilateral triangle inscribed in the intersection of the unit hypersphere and a hyperplane containing the origin.
Fix a 3-coloring and assign one of the three vertices of the triangle as the vector of each vetex in $V$ so that vertices are assigned the same vector iff they are assigned the same color.
Notice that all $v_i$ will be on this hypersphere because &quot;$v_i \cdot v_i = 1$ for all $i \in V$&quot;.
Now, we have $v_i \cdot v_j$ $=$ $\left\vert v_i \right\vert \left\vert v_j \right\vert \cos (\frac{2\pi}{3})$ $=$ $-\frac{1}{2}$.
Notice that angle is $\frac{2\pi}{3}$ because it's an equilateral triangle.

Then, we can design an algorithm like follow.
&lt;div class=&quot;algTab&quot;&gt;
    Solve algorithm above to obtain optimal solution $v_1, \cdots, v_n$&lt;br&gt;
    Choose vector $r_1, \cdots, r_t$ independently and uniformly at random from the unit hypersphere where $t = 2 + \log_3 \Delta$.&lt;br&gt;
    Divides the hyper sphere into $2^t$ different regions by half space $H_i = \{x | x \cdot r_i \ge 0\}$ for $0$ $\le$ $i$ $\le$ $t$&lt;br&gt;
    Assign a distinct color for all vectices in each resign.
&lt;/div&gt;

Polynomial running time of semidefinitive program/random picking will be updated later.
Then, all other process will be in the polynomial time.
Notice that this algorithm uses $2^t$ $=$ $2^{2 + \log_3 \Delta}$ $=$ $4 \times 2^{\log_3 \Delta}$ $=$ $4 {\Delta}^{\log_3 2}$ colors.
Therefore, it's enough to show that this makes a semicoloring with $\frac{1}{2}$ probability.

Now, let's think about edge $e$ $=$ $(v_i, v_j)$.
With this, consider some $H_k$ and $r^{\star}_k$.
Which $r^{\star}_k$ is the projection of $r_k$ on to the plane defined by $v_i, v_j, 0$.
Then, $v_i \cdot r_k$ $=$ $v_i \cdot r^{\star}_k$ and $v_i \cdot r_k$ $=$ $v_i \cdot r^{\star}_k$.
Notice that $r_k$ can be decomposed to $r^{\star}_k$ and $r^{\circ}_k$.
Then, $v_i \cdot r_k$ $=$ 
$v_i \cdot (r^{\star}_k + r^{\circ}_k)$ $=$ 
$v_i \cdot r^{\star}_k$ $+$ $v_i \cdot r^{\circ}_k$ $=$
$v_i \cdot r^{\star}_k$.
This works in the same way for $v_j$ either.
Now, $Pr[\text{Both } v_i \text{ and } v_j \text{ are in the } H_k]$ $=$
$Pr[\text{Both } v_i \cdot r_k \text{ and } v_j \cdot r_k \text{ has the same sign}]$ $=$ 
$Pr[\text{Both } v_i \cdot r^{\star}_k \text{ and } v_j \cdot r^{\star}_k \text{ has the same sign}]$

Then, $Pr[\text{Both } v_i \cdot r^{\star}_k \text{ and } v_j \cdot r^{\star}_k \text{ has the same sign}]$ $=$ $\frac{\pi - \theta}{\pi}$ which $\theta$ is the angle between $v_i$ and $v_j$.
Proof is like follow.
Let's denote $\theta_i, \theta_j, \theta_k$ as the angle of $v_i, v_j, r^{\star}_k$.
Then, there are two cases for $\theta_k$ which both $v_i \cdot r^{\star}_k$ and $v_j \cdot r^{\star}_k$ are positive or negative.
With this two cases, there are 2 cases per each case for each of them from criteria &quot;$\theta_i = \theta_j + \pi$&quot; to choose the range of possible angle.
Therefore, there are 4 cases in total.

1. $\theta_j - \frac{\pi}{2}$ $\le$ $\theta_k$ $\le$ $\theta_i + \frac{\pi}{2}$ if $\theta_i$ $\le$ $\theta_j$ $\le$ $\theta_i$ $+$ $\pi$ and both $v_i \cdot r^{\star}_k$ and $v_j \cdot r^{\star}_k$ are positive.
2. $\theta_j + \frac{\pi}{2}$ $\le$ $\theta_k$ $\le$ $\theta_i + \frac{3\pi}{2}$ if $\theta_i$ $\le$ $\theta_j$ $\le$ $\theta_i$ $+$ $\pi$ and both $v_i \cdot r^{\star}_k$ and $v_j \cdot r^{\star}_k$ are negative.
3. $\theta_i - \frac{\pi}{2}$ $\le$ $\theta_k$ $\le$ $\theta_j + \frac{\pi}{2}$ if $\theta_i$ $-$ $\pi$ $\le$ $\theta_j$ $\le$ $\theta_i$ and both $v_i \cdot r^{\star}_k$ and $v_j \cdot r^{\star}_k$ are positive.
4. $\theta_i + \frac{\pi}{2}$ $\le$ $\theta_k$ $\le$ $\theta_j + \frac{3\pi}{2}$ if $\theta_i$ $-$ $\pi$ $\le$ $\theta_j$ $\le$ $\theta_i$ and both $v_i \cdot r^{\star}_k$ and $v_j \cdot r^{\star}_k$ are negative.

Then, we can know claim holds in each cases.

1. $2\pi Pr[\text{Both } v_i \cdot r^{\star}_k \text{ and } v_j \cdot r^{\star}_k \text{ has the same sign}]$ $=$
$(\theta_i + \frac{\pi}{2})$ $-$ $(\theta_j - \frac{\pi}{2})$ $+$ $(\theta_i + \frac{3\pi}{2})$ - $(\theta_j + \frac{\pi}{2})$  $=$
$2(\theta_i - \theta_j)$ $+$ $2\pi$ $=$
$2(\pi + \theta_i - \theta_j)$ $=$
$2(\pi - (\theta_j - \theta_i))$
if $\theta_i$ $\le$ $\theta_j$ $\le$ $\theta_i$ $+$ $\pi$.
As a result, $Pr[\text{Both } v_i \cdot r^{\star}_k \text{ and } v_j \cdot r^{\star}_k \text{ has the same sign}]$ $=$ 
$\frac{\pi - (\theta_j - \theta_i)}{\pi}$.
Therefore claim holds in this case.
2. $2\pi Pr[\text{Both } v_i \cdot r^{\star}_k \text{ and } v_j \cdot r^{\star}_k \text{ has the same sign}]$ $=$
$(\theta_j + \frac{\pi}{2})$ $-$ $(\theta_i - \frac{\pi}{2})$ $+$ $(\theta_j + \frac{3\pi}{2})$ $-$ $(\theta_i + \frac{\pi}{2})$ $=$
$2(\theta_j - \theta_i)$ $+$ $2\pi$ $=$
$2(\pi + \theta_j - \theta_i)$ $=$
$2(\pi - (\theta_i - \theta_j))$
if $\theta_i$ $-$ $\pi$ $\le$ $\theta_j$ $\le$ $\theta_i$.
As a result, $Pr[\text{Both } v_i \cdot r^{\star}_k \text{ and } v_j \cdot r^{\star}_k \text{ has the same sign}]$ $=$ 
$\frac{\pi - (\theta_i - \theta_j)}{\pi}$.
Therefore claim holds in this case.

Notice that $Pr[\text{Both } v_i \text{ and } v_j \text{ are in the } H_k]$ $=$
$\frac{\pi - \theta}{\pi}$ $=$
$1$ $-$ $\frac{\theta}{\pi}$ $=$
$1$ $-$ $\frac{\arccos(v_i \cdot v_j)}{\pi}$ $=$
$1$ $-$ $\frac{1}{\pi}\arccos(v_i \cdot v_j)$.

Therefore, $Pr[\text{Both } i \text{ and } j \text{ assigned to the same color}]$ $=$ 
$Pr[\text{Both } v_i \text{ and } v_j \text{ are in the same reigon for all half space}]$ $=$ 
$(1 - \frac{1}{\pi}\arccos(v_i \cdot v_j))^t$.
With above, there are two facts from semidefinitive program and proof above.
1. $v_i \cdot v_j \le \lambda$ for all $(i, j) \in E$
2. There is a feasible solution such that $v_i \cdot v_j$ $=$ $-\frac{1}{2}$ for all $(i,j) \in E$ 

Now let's denote semidefinitive program optimum's $\lambda$ as ${\lambda}^{\star}$.
Then, ${\lambda}^{\star}$ $\le$ $-\frac{1}{2}$ because semidefinitive program was minimization problem.

Therefore, $Pr[\text{Both } i \text{ and } j \text{ assigned to the same color}]$ $=$
$(1 - \frac{1}{\pi}\arccos(v_i \cdot v_j))^t$ $\le$
$(1 - \frac{1}{\pi}\arccos({\lambda}^{\star}))^t$ $\le$
$(1 - \frac{1}{\pi}\arccos(-\frac{1}{2}))^t$ $=$
$(1 - \frac{1}{\pi}\frac{2\pi}{3})^t$ $=$
$(1 - \frac{2}{3})^t$ $=$
$(\frac{1}{3})^{2 + \log_3 \Delta}$ $=$
$\frac{1}{9\Delta}$.

Notice that $\arccos x$ is a monotonic decreasing function for $-1$ $\le$ $x$ $\le$ $1$.
Therefore, $1$ $-$ $\frac{1}{\pi}\arccos x$ is a monotonic increasing function.

Now, sum of degree is $2\left\vert E \right\vert$ and possible maximum sum of degree is $n\Delta$.
Therefore, $2\left\vert E \right\vert$ $\le$ $n\Delta$ which means $\frac{\left\vert E \right\vert}{\Delta}$ $\le$ $\frac{n}{2}$.
As a result, expected number of edges whose endpoints are colred the same is at most $\left\vert E \right\vert \frac{1}{9\Delta}$ $\=$ $\frac{\left\vert E \right\vert}{9\Delta}$ $\le$ $\frac{n}{18}$.

Then, $Pr[X \ge \frac{n}{4}]$ $\le$ $\frac{E[X]}{n/4}$ $=$ $\frac{4}{n}E[X]$ $\le$ $\frac{4}{n}\frac{n}{18}$ $=$ $\frac{2}{9}$ $\le$ $\frac{1}{2}$ with markov's inequality where $X$ denotes number of edges where endpoiunts are colored the same.
Therefore claim holds.

&lt;br&gt;

Theorem 8 can be done by following algorithm.
Let $\sigma = n^{\log_6 3}$.
&lt;div class=&quot;algTab&quot;&gt;
    Let's call the below part as &quot;part 1&quot;&lt;div class=&quot;algTab&quot;&gt;
        $\operatorname{while} \exists$ a vertex $v$ with degree $\ge$ $\sigma$&lt;div class=&quot;algTab&quot;&gt;
            Color $v$ and it's neighbors using three new colors&lt;br&gt;
            Remove the colored vertices
        &lt;/div&gt;
    &lt;/div&gt;
    Let's call the below part as &quot;part 2&quot;&lt;div class=&quot;algTab&quot;&gt;
        $\operatorname{while}$ the graph is not empty, repeat at most $\log_2 n$ times&lt;div class=&quot;algTab&quot;&gt;
           Try running Algorithm at theorem 7 with $[\log_2(\log_2 n)] + 1$ times to find a semicoloring&lt;br&gt;
           $R \leftarrow$ endpoints of edges whose endpoints are colored the same&lt;br&gt;
           Color $V - R$ according to the semicoloring, using new colors&lt;br&gt;
           Remove the colored vetices
        &lt;/div&gt;
    &lt;/div&gt;
    Color the remaining vertices with distinct new colors
&lt;/div&gt;

Now, it is trivial that this algorithm runs in a polynomial time.
Therefore, it is enough to show it returns $\tilde{O}(n^{\log_6 2})$-coloring at least $\frac{1}{2}$ probability.
Now, let's think about part 1.
Then, maximum number of iteration is at most $[\frac{n}{\sigma}] + 1$ because it remvoes at least $\sigma$ vertices at once.
Therefore, color used at part 1 is at most $3([\frac{n}{\sigma}] + 1)$.
Now, let's think about part 2.
Left part of graph has at most $\sigma$ degree because we removed every possible vertices with more than degree $\sigma$.
Now, let's denote the maximum of degree after part 1 as $\Delta$ and the number of vertices as $n'$.
If we see each iteration, it fails to find a semicoloring with $(\frac{1}{2})^{[\log_2(\log_2 n)] + 1}$ probability.
Which is $(\frac{1}{2})^{[\log_2(\log_2 n)] + 1}$ $=$
$(2)^{-[\log_2(\log_2 n)] - 1}$ $\le$
$(2)^{-\log_2(\log_2 n) - 1}$ $=$
$(2)^{-\log_2(\log_2 n)}\frac{1}{2}$ $=$
$(2)^{\log_2(\log_2 n)^{-1}}\frac{1}{2}$ $=$
$(\log_2 n)^{-1}\frac{1}{2}$ $=$
$\frac{1}{2\log_2 n}$.
Therefore, it fails at most $\frac{1}{2\log_2 n}$ probability.
As a result, this algorithm success to find a semicoloring in every iteration at least $(1 - \frac{1}{2\log_2 n})^{\log_2 n}$ $\ge$ $\frac{1}{2}$ probability if $n$ $\ge$ $2$.

Proof is like follow.
Notice that if we change $log_2 x$ to $t$ then $(1 - \frac{1}{2\log_2 n})^{\log_2 n}$ $=$ $(1 - \frac{1}{2t})^{t}$.
Now it can be derivated easily about $t$ and result will be $(1 - \frac{1}{2t})(\ln(1 - \frac{1}{2t}) + \frac{1}{2t - 1})$.
Notice that $t \ge 1$.
Then, $1 - \frac{1}{2t} \ge 0$ because $t \ge 1$.
For the other part, $\ln(1 - \frac{1}{2t})$ $+$ $\frac{1}{2t - 1}$ $=$ 
$\ln(\frac{2t - 1}{2t})$ $+$ $\frac{1}{2t - 1}$ $=$ 
$\ln(\frac{2t - 1}{2t})$ $+$ $\frac{2t}{2t - 1}$ $-$ $\frac{2t - 1}{2t - 1}$ $=$
$\ln(\frac{2t - 1}{2t})$ $+$ $\frac{2t}{2t - 1}$ $-$ $1$ $=$
$\ln X$ $+$ $\frac{1}{X}$ $-$ $1$.
for $X$ $=$ $\frac{2t -1}{2t}$.
Notice that $0$ $&lt;$ $X$ $&lt;$ $1$.
Then, $\ln X$ $+$ $\frac{1}{X}$ $-$ $1$ $\ge$ $0$.
Proof is like follow.
If we derivated $y$ $=$ $\ln X$ $+$ $\frac{1}{X}$ $-$ $1$, $y'$ $=$ $\frac{1}{X}$ $-$ $\frac{1}{X^2}$ $=$ $\frac{X - 1}{X^2}$.
As a result, $y$ decreases in $0$ $&lt;$ $X$ $&lt;$ $1$.
However, it's zero when $X$ $=$ $1$.
Therefore, $\ln X$ $+$ $\frac{1}{X}$ $-$ $1$ $\ge$ $0$.
As a result, this algorithm success to find a semicoloring in every iteration at least $\frac{1}{2}$ probability if $n$ $\ge$ $2$.

Now, it doesn't have too much meaning if you think about $n$ $=$ $1$.
Therefore, assumption isn't too tight.

Now, let's see how many vertices are removed at each iteration.
If we start with $n'$ vertices, $\left\vert R \right\vert$ $\le$ $2 \frac{n'}{4}$ $=$ $\frac{n'}{2}$.
As a result, it will reduce to be half at least.
Therefore, there will be at most $O(1)$ vertices after part 2.
Notice that we will do part 2 at most $log_2 n$ time and it will be enough to be so.

As a result color used in each part is like follow.
1. Part 1 uses at most $3([\frac{n}{\sigma}] + 1)$ $=$
$3([\frac{n}{n^{\log_6 3}}] + 1)$ $\le$
$3(\frac{n}{n^{\log_6 3}} + 1)$ $=$
$3(\frac{n^{\log_6 6}}{n^{\log_6 3}} + 1)$ $=$
$3(n^{\log_6 2} + 1)$ colors.
2. Part 2 uses at most $4\Delta^{\log_3 2}(\log_2 n)$ $\le$
$4\sigma^{\log_3 2}(\log_2 n)$ $=$
$4(n^{\log_6 3})^{\log_3 2}(\log_2 n)$ $=$
$4n^{\log_6 3 \cdot \log_3 2}(\log_2 n)$ $=$
$4n^{\log_6 2}(\log_2 n)$ colors.
3. Left part will use at most $O(1)$ colors.

As a result, algorithm uses at most $3n^{\log_6 2}$ $+$ $3$ $+$ $4n^{\log_6 2}(\log_2 n)$ $+$ $O(1)$.
Therefore, claim holds.</content><author><name>Programelot</name></author><category term="algorithm" /><category term="approximation" /><summary type="html">We need some definitions and theorems to discuss about the coloring.</summary></entry><entry><title type="html">Markov’s inequality</title><link href="https://programelot.github.io/2021/05/14/Markovs-inequality/" rel="alternate" type="text/html" title="Markov's inequality" /><published>2021-05-14T00:00:00+09:00</published><updated>2021-05-14T00:00:00+09:00</updated><id>https://programelot.github.io/2021/05/14/Markovs%20inequality</id><content type="html" xml:base="https://programelot.github.io/2021/05/14/Markovs-inequality/">If $X$ is a nonnegative random variable and $a \gt 0$ then,
$Pr[X \ge a]$ $\le$ $\frac{E(X)}{a}$.

Proof is like follow.
First of all, $E(X | X \ge a)$ $\ge$ $a$ because condition means that varaible is greater or equal than $a$.
Simillary, $E(X | X \lt a)$ $\ge$ $0$ because $X$ is a nonnegative random variable.
Then, $E(X)$ $=$ $Pr[X \lt a] \cdot E(X | X \lt a)$ $+$ $Pr[X \ge a] \cdot E(X | X \ge a)$ $\ge$ $Pr[X \ge a] \cdot E(X | X \ge a)$ $\ge$ $Pr[X \ge a] \cdot a$.
Therefore, claim holds</content><author><name>Programelot</name></author><category term="algorithm" /><category term="approximation" /><summary type="html">If $X$ is a nonnegative random variable and $a \gt 0$ then, $Pr[X \ge a]$ $\le$ $\frac{E(X)}{a}$.</summary></entry></feed>